---
layout: post
title: "arXiv Daily – 2026-01-14"
tags: [arxiv, cs.SD, eess.AS]
---

以下为 2026-01-14（CST，北京时间）窗口内更新的论文中文译文：
- 时间窗口（锚点 08:50 CST）：2026-01-13 08:50 — 2026-01-14 08:50
- 抓取总数：6 篇 | 本页显示：6 篇（去重/过滤后）

## FusID: Modality-Fused Semantic IDs for Generative Music Recommendation
- **Authors**: Haven Kim, Yupeng Hou, Julian McAuley
- **Categories**: cs.IR, cs.SD, eess.AS
- **arXiv**: [https://arxiv.org/abs/2601.08764v1](https://arxiv.org/abs/2601.08764v1)
- **PDF**: [https://arxiv.org/pdf/2601.08764v1](https://arxiv.org/pdf/2601.08764v1)

生成式推荐系统通过利用语义ID表示物品已取得显著进展。然而，现有独立对多模态进行标记的方法存在两个关键局限：(1) 跨模态冗余导致效率降低，(2) 未能捕捉模态间交互从而限制物品表征能力。本文提出FusID——一种模态融合语义ID框架，通过三个核心组件解决上述问题：(i) 多模态融合模块通过跨模态联合编码学习统一表征，(ii) 表征学习模块使高频共现的物品嵌入相互靠近，同时保持特征区分度并防止冗余，(iii) 乘积量化模块将融合后的连续嵌入转换为多个离散标记以缓解ID冲突。在多模态下一首歌曲推荐（即歌单延续）基准测试中，FusID实现了零ID冲突（确保每个标记序列精确对应单曲），缓解了码本利用率不足的问题，并在MRR与Recall@k（k = 1, 5, 10, 20）指标上超越基线方法。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：生成式推荐系统利用语义ID表示物品，但在多模态场景下面临挑战。
- **既有方法问题**：
  - **冗余问题**：现有方法为每个模态（如音频、标签、歌词）独立学习分词器，导致相似语义信息被重复编码，造成词汇表过大，增加计算开销。
  - **模态割裂**：独立编码无法捕捉不同模态间的交互与互补信息（如音频情感与歌词主题的关联），限制了物品表示的全面性与区分度。

2)  
FusID通过三个核心组件解决上述问题：
- **多模态融合**：设计一个简单的融合网络，将多个模态的特征（如标签、元数据、歌词、音频、播放列表共现）联合编码，学习跨模态的交互信息，生成统一的表示，避免信息割裂。
- **表示学习**：
  - **对比损失**：使频繁共现的物品嵌入在上下文中更接近，而罕见共现的则相互远离，以捕捉物品间的语义关联。
  - **正则化损失**：包含协方差损失和方差损失，确保所有子嵌入携带互补信息、防止特征重叠，并避免嵌入坍缩，从而减少冗余、保持独特性。
- **乘积量化**：将融合后的连续嵌入分解为多个子空间，通过k-means聚类为每个子嵌入分配离散令牌，生成组合语义ID。这种设计确保了每个令牌序列唯一映射到一个物品，实现了零ID冲突，并缓解了码本未充分利用问题。

3)  
- **任务**：多模态下一首歌曲推荐（即播放列表延续）。
- **效果**：
  - **语义ID质量**：在百万播放列表数据集上，实现了零ID冲突、近乎完美的码本利用率（测试集仅0.02%未使用），并编码了所有歌曲（完美基数）。
  - **生成推荐性能**：在MRR和Recall@k（k=1,5,10,20）指标上均超越基线（如TalkPlay），例如MRR提升6.21%，Recall@k提升6.09%-6.46%，验证了高质量语义ID对生成式推荐的有效性。
</div>

</details>

---

## Weakly Supervised Tabla Stroke Transcription via TI-SDRM: A Rhythm-Aware Lattice Rescoring Framework
- **Authors**: Rahul Bapusaheb Kodag, Vipul Arora
- **Categories**: eess.AS
- **arXiv**: [https://arxiv.org/abs/2601.08537v1](https://arxiv.org/abs/2601.08537v1)
- **PDF**: [https://arxiv.org/pdf/2601.08537v1](https://arxiv.org/pdf/2601.08537v1)

塔布拉鼓点转录是分析印度斯坦古典音乐节奏结构的核心任务，但由于复杂的节奏组织及强标注数据的稀缺，该任务仍具挑战性。现有方法主要依赖基于起始点级别标注的全监督学习，这类标注成本高昂且难以大规模应用。本研究针对弱监督场景下的塔布拉鼓点转录问题，仅使用未进行时间对齐的符号化鼓点序列。我们提出一种结合CTC声学模型与序列级节奏重评分的框架：声学模型生成解码网格后，通过一种**独立于塔拉节奏周期的静态-动态节奏模型**进行优化，该模型采用自适应插值机制融合长期节奏结构与短期动态适应性。我们构建了一个新的真实世界塔布拉独奏数据集及配套合成数据集，首次为印度斯坦古典音乐中的弱监督鼓点转录建立了基准。实验表明，相比仅使用声学解码的方法，本框架能持续显著降低鼓点错误率，证实了显式节奏结构对准确转录的重要性。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：塔布拉鼓（Tabla）是北印度古典音乐的核心打击乐器，其自动音符转录（TST）对分析节奏结构至关重要。  
- **既有方法问题**：现有方法主要依赖**完全监督学习**，需要精确的起始时间标注，这类数据**获取成本高、难以大规模应用**。同时，先前对弱监督（仅使用音符序列，无时间对齐）的研究**几乎空白**，仅有的初步工作也受限于**恒定速度的假设**，不适用于真实演奏。

2)  
论文提出一个结合声学模型与节奏感知序列重评分的弱监督框架，核心是 **TI-SDRM（Tala无关的静态-动态节奏模型）**。该方法通过以下机制解决标注稀缺和节奏建模问题：  
- **声学建模**：使用**CTC（连接时序分类）** 训练声学模型，仅需音符序列监督，无需时间对齐，生成包含多种可能序列的解码网格。  
- **节奏重评分**：在解码网格上，TI-SDRM 进行序列级节奏校正，具体包括：  
  - **静态节奏先验**：基于不同塔拉（tala）训练 n-gram 音符模型，捕捉**长期节奏结构**；测试时通过**隐变量边缘化**实现塔拉无关的先验概率。  
  - **动态贝叶斯模型**：采用狄利克雷-多项分布，通过**指数遗忘机制**在线更新，适应**短期局部节奏变化**（如即兴演奏）。  
  - **自适应插值**：根据**声学置信度**（网格局部熵）和**节奏差异**（Jensen-Shannon散度）动态加权静态与动态组件，使模型在声学可靠且节奏预测分歧大时更依赖动态信息。  
- **网格重评分与状态扩展**：遍历声学网格时，通过**状态扩展**保留历史相关的节奏上下文，使用结合声学分数与节奏概率的得分进行重评分，最终通过维特比解码输出转录序列。

3)  
- **任务**：弱监督塔布拉鼓音符转录（仅使用符号序列标注，无起始时间）。  
- **效果**：在多个数据集（包括新构建的真实与合成数据集）上评估，使用**音符错误率（SER）** 衡量。TI-SDRM 相比纯声学解码**一致且显著降低错误率**，相对提升最高超过 **35%**。例如，在包含音乐会录音的数据集上，错误率从 43.8% 降至 30.4%。实验表明，**显式节奏建模对提升转录准确性至关重要**，尤其在低资源和声学证据不可靠的情况下。
</div>

</details>

---

## Robust CAPTCHA Using Audio Illusions in the Era of Large Language Models: from Evaluation to Advances
- **Authors**: Ziqi Ding, Yunfeng Wan, Wei Song, Yi Liu, Gelei Deng, Nan Sun, Huadong Mo, Jingling Xue, Shidong Pan, Yuekang Li
- **Categories**: cs.SD, cs.CY, eess.AS
- **arXiv**: [https://arxiv.org/abs/2601.08516v1](https://arxiv.org/abs/2601.08516v1)
- **PDF**: [https://arxiv.org/pdf/2601.08516v1](https://arxiv.org/pdf/2601.08516v1)

CAPTCHA（全自动区分计算机和人类的公开图灵测试）被网站广泛用于通过呈现人类易于解决但自动化程序难以应对的挑战来拦截机器人和垃圾信息。为提高可访问性，音频CAPTCHA被设计为视觉CAPTCHA的补充。然而，音频CAPTCHA在面对先进的大规模音频语言模型和自动语音识别模型时的鲁棒性尚不明确。

本文提出AI-CAPTCHA这一统一框架，包含：（1）评估框架ACEval，集成基于先进LALM和ASR的求解器；（2）新型音频CAPTCHA方法IllusionAudio，利用听觉错觉原理。通过对七种广泛部署的音频CAPTCHA进行大规模评估，我们发现现有方法大多能被先进LALM和ASR模型以高成功率破解，暴露出严重的安全缺陷。

为应对这些漏洞，我们设计了新型音频CAPTCHA方法IllusionAudio，该方法基于人类听觉机制中的感知错觉线索构建。大量实验表明，我们的方法能有效抵御所有已测试的LALM和ASR攻击，同时实现100%的人类通过率，显著优于现有音频CAPTCHA方案。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：音频验证码（CAPTCHA）旨在为视觉障碍者提供无障碍访问，并抵御自动化攻击。现有方法主要分为两类：基于内容的（要求转录语音）和基于规则的（要求遵循指令或推理）。  
- **既有问题**：随着大型音频语言模型（LALMs）和自动语音识别（ASR）技术的进步，这些模型在嘈杂、失真语音上的表现已接近人类，导致现有音频验证码的安全假设受到挑战。论文指出，当前部署的音频验证码可能无法有效区分人类用户与AI驱动的自动化求解器。

2)  
论文提出了 **AI-CAPTCHA** 统一框架，包含两个核心组件以解决上述问题：  
- **ACEVAL（评估框架）**：  
  - 集成了两类AI求解器进行系统评估：  
    - **LALM-based求解器**：直接对音频输入进行端到端推理，代表新型攻击方式。  
    - **ASR-based求解器**：采用两阶段流程，先用ASR转录音频，再用大语言模型（LLM）处理文本以生成最终答案。  
  - 该框架用于全面评估现有音频验证码的鲁棒性，揭示了它们对AI攻击的脆弱性。  
- **ILLUSIONAUDIO（新型音频验证码设计）**：  
  - **核心机制**：利用**正弦波语音错觉**——一种人类听觉感知现象，即人类能从稀疏的正弦波信号中识别语音，而AI模型缺乏依赖的频谱特征。  
  - **增强设计**：  
    - 引入**不可逆转换模块**（如随机下采样），进一步破坏信号的可重构性，防止基于振幅等低层次启发式攻击。  
    - 采用**选项式交互**（非转录式），动态随机化任务和选项组合，提升用户体验并抵御模式学习。  
    - 提供**干净参考音频**作为感知“提示”，确保人类用户能轻松解码错觉音频，实现高可用性。  
  - **效果**：通过感知不对称性，在保持人类可解性的同时，有效抵御所有测试的LALM和ASR攻击。

3)  
- **评估任务**：在七种广泛部署的音频验证码（包括4种基于内容和3种基于规则）上进行测试。  
- **效果**：  
  - **安全性**：ILLUSIONAUDIO在所有测试的LALM和ASR攻击下实现了**0%绕过率**，显著优于现有方案（后者绕过率最高达100%）。  
  - **可用性**：在63名参与者（含视觉障碍者）的用户研究中，ILLUSIONAUDIO取得了**100%首次尝试成功率**，远超现有方案（平均首次尝试成功率仅61.90%），实现了安全性与用户体验的平衡。
</div>

</details>

---

## Quantitative Analysis of Proxy Tasks for Anomalous Sound Detection
- **Authors**: Seunghyeon Shin, Seokjin Lee
- **Categories**: eess.AS
- **arXiv**: [https://arxiv.org/abs/2601.08480v1](https://arxiv.org/abs/2601.08480v1)
- **PDF**: [https://arxiv.org/pdf/2601.08480v1](https://arxiv.org/pdf/2601.08480v1)

异常声音检测（ASD）通常采用自监督代理任务从正常声音数据中学习特征表示，这主要是由于异常样本的稀缺性。在ASD研究中，诸如自编码器等代理任务基于一个明确假设：在正常数据上训练的模型会增加与异常相关的重构误差。一个自然的延伸推论是，代理任务性能的提升应能增强ASD能力；然而，这一关系鲜少得到系统性关注。本研究通过定量分析代理任务指标与ASD性能之间的关系来填补这一研究空白，涵盖了自编码器、分类、源分离、对比学习和预训练模型五种配置。我们使用线性探针（线性可分性）和马氏距离（分布紧致性）评估学习到的表示。实验表明，强大的代理任务性能并不必然提升异常声音检测性能。具体而言，分类任务因任务难度不足而出现性能饱和，而对比学习则因数据多样性有限未能学习到有意义的特征。值得注意的是，源分离是唯一表现出强正相关性的任务，即分离性能的提升持续改善异常检测效果。基于这些发现，我们强调了任务难度与目标对齐的关键重要性。最后，我们提出了一个三阶段对齐验证协议，以指导为ASD系统设计高效的代理任务。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：异常声音检测通常依赖自监督代理任务，因为异常样本稀缺。现有方法（如自编码器）隐含假设：代理任务性能提升会改善异常检测能力，但此关系缺乏系统验证。
- **既有问题**：代理任务性能与异常检测能力之间的关联不明确，导致设计代理任务时可能盲目优化代理指标，而无法保证异常检测效果提升。

2)  
- **核心方法**：本研究首次系统分析了五种代理任务与异常检测性能的定量关系，包括自编码器、分类、源分离、对比学习和预训练模型。
- **解决方式**：
  - **多维度评估**：使用线性探针（评估线性可分性）和马氏距离（评估分布紧密度）综合评估学习到的特征表示。
  - **定量相关性分析**：通过斯皮尔曼等级相关系数，量化代理任务指标与异常检测性能之间的关联。
  - **关键发现**：
    - 仅源分离任务显示强正相关，即分离质量提升直接改善异常检测性能。
    - 分类任务因任务过于简单导致性能饱和，代理指标失去判别力。
    - 对比学习因数据多样性不足导致模型崩溃，无法学习有效特征。
    - 自编码器仅与分布紧密度相关，与线性可分性无关。
  - **设计原则**：强调代理任务的**难度适宜性**和**目标对齐**的重要性，并提出三阶段对齐验证协议指导代理任务设计。

3)  
- **任务与效果**：
  - 在ToyADMOS2和MIMII数据集上，评估了七种机器类型的异常声音检测。
  - **源分离**：代理任务性能与所有异常检测指标（线性探针、马氏距离）均呈强正相关，显著提升检测性能。
  - **其他任务**：自编码器在线性探针上表现稳健，但代理指标提升不保证检测性能改善；分类和对比学习未显示显著相关性；预训练模型的通用音频分类性能与异常检测能力不一致。
  - **整体贡献**：明确了代理任务与异常检测的对齐条件，为设计高效代理任务提供了实证依据。
</div>

</details>

---

## Decoding Order Matters in Autoregressive Speech Synthesis
- **Authors**: Minghui Zhao, Anton Ragni
- **Categories**: cs.SD, cs.AI, eess.AS
- **arXiv**: [https://arxiv.org/abs/2601.08450v1](https://arxiv.org/abs/2601.08450v1)
- **PDF**: [https://arxiv.org/pdf/2601.08450v1](https://arxiv.org/pdf/2601.08450v1)

自回归语音合成通常采用从左到右的生成顺序，但生成顺序本身是一种建模选择。本研究通过掩码扩散框架探讨解码顺序的影响，该框架逐步解除位置掩码，并允许在训练和推理阶段采用任意解码顺序。通过在恒等排列与随机排列之间进行插值实验，我们发现解码顺序的随机性会影响语音质量。进一步比较固定顺序策略（如从左到右和从右到左）与自适应策略（如Top-$K$）后发现，包括主流从左到右方法在内的固定顺序解码并非最优，而自适应解码能获得更好的性能。最后，由于掩码扩散需要离散输入，我们对声学表示进行量化，发现即使1比特量化也能支持较高质量的语音合成。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：自回归语音合成（如WaveNet、Tacotron 2）普遍采用从左到右的解码顺序，这被视为默认选择。然而，语音的依赖关系（如停顿、强调、协同发音）往往超出简单的因果链，全局上下文和未来信息也可能影响当前帧的生成。  
- **既有方法的问题**：固定的左到右顺序可能不是最优的，因为它限制了模型如何利用上下文信息。此外，为不同固定顺序训练单独模型效率低下（有T!种可能），且无法在同一框架内直接比较不同顺序的效果。  

2)  
- **核心框架**：本文采用掩码扩散模型作为基础框架。该模型在训练时随机掩码并重建语音帧，从而实现对任意解码顺序的“顺序无关”训练。在推理时，可以自由指定解码顺序σ（如从左到右、从右到左、随机顺序或自适应顺序），逐步“揭开”掩码位置以生成语音。  
- **量化处理**：由于MDM适用于离散数据，作者对梅尔频谱图进行了线性量化（即使1比特量化也能产生可理解的语音），将每个帧视为一个高维离散令牌。  
- **解码策略创新**：  
  - **控制随机性**：通过在恒等排列（左到右）和随机排列之间插值，调节解码顺序的随机程度，研究随机性对语音质量的影响。  
  - **自适应策略**：提出Top-K概率策略，每一步根据模型对未解码位置的置信度分数（基于预测概率的最大对数概率之和）动态选择下一个要解码的位置（或前K个位置），实现内容感知的解码。  
  - **时长引导解码**：利用时长预测器划分语音段，选择平均置信度最高的段，优先解码该段内的帧，从而更贴合语音的语义结构。  
- **解决既有问题的方式**：  
  - **打破固定顺序限制**：MDM框架允许在训练和推理中灵活采用任意顺序，从而能够系统比较不同顺序的效果。  
  - **提升上下文利用效率**：自适应策略（如Top-K）让模型可以根据当前已解码内容动态决定下一步解码哪里，更有效地捕捉局部或全局依赖关系。  
  - **保持训练效率**：通过ELBO目标函数，只需对随机采样的掩码模式进行并行重建，避免了为每种顺序训练独立模型的计算负担。  

3)  
- **任务与效果**：在LJSpeech数据集上的语音合成任务中，通过梅尔倒谱失真、对数F0、UTMOSv2和平均意见得分等指标评估：  
  - **固定顺序对比**：从右到左顺序在多项指标上优于传统的从左到左顺序，证明后者并非最优。  
  - **自适应策略优势**：Top-K（特别是带采样的top1*）和时长引导解码策略在客观指标和主观MOS上表现最佳，超过了所有固定顺序策略。  
  - **量化发现**：即使使用1比特量化梅尔频谱图，结合HiFi-GAN声码器仍能产生可理解的语音，表明语音表示的强冗余性。
</div>

</details>

---

## Decodable but not structured: linear probing enables Underwater Acoustic Target Recognition with pretrained audio embeddings
- **Authors**: Hilde I. Hummel, Sandjai Bhulai, Rob D. van der Mei, Burooj Ghani
- **Categories**: cs.LG, cs.SD, eess.AS
- **arXiv**: [https://arxiv.org/abs/2601.08358v1](https://arxiv.org/abs/2601.08358v1)
- **PDF**: [https://arxiv.org/pdf/2601.08358v1](https://arxiv.org/pdf/2601.08358v1)

日益加剧的船舶人为噪声显著加剧了水下声污染，对海洋生态系统构成威胁。因此，监测船舶辐射噪声的影响至关重要，以理解和量化其影响。被动声学监测系统为此被广泛部署，在不同声景中积累了多年的水下录音数据。由于人工分析此类大规模数据不切实际，基于机器学习的自动化方法成为必要。近年来，水下声学目标识别领域的进展主要依赖于监督学习，但受限于标注数据的稀缺。迁移学习为缓解这一限制提供了有前景的替代方案。本研究首次对水下声学目标识别的迁移学习进行了实证比较，评估了来自不同音频领域的多种预训练音频模型。预训练模型的权重被冻结，通过分类、聚类和相似性评估对生成的嵌入向量进行分析。分析表明，嵌入空间的几何结构主要由录音特异性特征主导。然而，简单的线性探针能够有效抑制这些录音特异性信息，并从嵌入中分离出船舶类型特征。因此，线性探针能够以较低的计算成本，利用预训练音频模型实现有效的水下声学目标识别，显著减少对大量高质量标注船舶录音的需求。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：船舶产生的人为噪声加剧了水下声污染，威胁海洋生态系统。被动声学监测系统产生大量水下录音，但人工分析不切实际，需自动化方法。  
- **既有方法问题**：现有水下声学目标识别主要依赖监督学习，但标记数据稀缺，且现有数据集覆盖区域小、环境多样性有限，导致模型泛化能力差，难以适应新船舶或不同海洋环境。  

2)  
- **核心方法**：本研究首次对UATR进行迁移学习的实证比较研究。方法包括：  
  - **模型选择与冻结**：选取来自不同音频领域（通用音频、语音、生物声学、海洋生物声音）的多个预训练模型，冻结其权重，将音频输入转换为嵌入向量。  
  - **嵌入空间分析**：通过三种互补方法评估嵌入向量的表征质量：  
    - **线性探测**：在嵌入向量上训练简单的线性分类器进行船舶类型分类。  
    - **聚类分析**：使用K-Means对嵌入向量聚类，并通过标准化互信息评估聚类与真实标签的一致性。  
    - **相似性评估**：基于余弦相似度计算嵌入向量之间的相似性，并通过ROC-AUC评分评估同类样本的聚集程度。  
- **解决思路**：  
  - 研究发现，预训练模型的嵌入空间几何结构主要由录音特异性特征（如环境、设备差异）主导，而非船舶类型特征，这通过聚类和相似性评估得到验证。  
  - 然而，线性探测能有效抑制这些录音特异性信息，从嵌入向量中分离出船舶类型特征。线性层充当“特征选择器”，仅利用嵌入空间的一小部分子集进行分类，从而在少量标记数据下实现有效分类。  
  - 该方法避免了整个模型的微调，大幅减少可训练参数和计算成本，缓解了对大量高质量标记数据的需求。  

3)  
- **任务与效果**：在**船舶类型分类**任务上，使用两个基准数据集（Deepship和ShipsEar）进行评估：  
  - **Deepship**：最佳模型BEATS达到65.4%的准确率，优于基线模型（56.4%）。  
  - **ShipsEar**：最佳模型Wav2Vec2.0达到78.0%的准确率，BEATS为74.0%，显著超过基线（48.6%）。  
- **关键发现**：预训练自通用音频或生物声学领域的模型（如BEATS、BirdMAE）表现良好，而专为海洋生物声音设计的模型（如Google Whale）泛化能力较差。线性探测能以低成本实现有效分类，证明了迁移学习在UATR中的可行性。
</div>

</details>

---
