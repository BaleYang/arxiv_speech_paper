---
layout: post
title: "arXiv Daily – 2026-02-19"
tags: [arxiv, cs.SD, eess.AS]
---

以下为 2026-02-19（CST，北京时间）窗口内更新的论文中文译文：
- 时间窗口（锚点 08:50 CST）：2026-02-18 08:50 — 2026-02-19 08:50
- 抓取总数：11 篇 | 本页显示：11 篇（去重/过滤后）

## Scaling Open Discrete Audio Foundation Models with Interleaved Semantic, Acoustic, and Text Tokens
- **Authors**: Potsawee Manakul, Woody Haosheng Gan, Martijn Bartelds, Guangzhi Sun, William Held, Diyi Yang
- **Categories**: cs.SD, cs.CL, eess.AS
- **arXiv**: [https://arxiv.org/abs/2602.16687v1](https://arxiv.org/abs/2602.16687v1)
- **PDF**: [https://arxiv.org/pdf/2602.16687v1](https://arxiv.org/pdf/2602.16687v1)

当前音频语言模型大多以文本为主导，要么基于预训练文本大语言模型扩展，要么仅依赖语义音频标记，限制了通用音频建模能力。本文对原生音频基础模型进行了系统性实证研究，通过大规模音频下一标记预测，联合建模语义内容、声学细节与文本，以支持通用音频生成与跨模态能力。我们为构建此类模型提供了全面的实证洞见：（1）系统探究了数据源、文本混合比例与标记组合等设计选择，确立了经验证的有效训练方案。（2）通过对64个模型（计算量覆盖$3{\times}10^{18}$至$3{\times}10^{20}$ FLOPs）进行等计算量分析，首次揭示了离散音频模型的缩放规律，发现最优数据增长速度需达到最优模型规模的1.6倍。（3）基于上述发现训练了SODA模型系列（参数规模1.35亿至40亿，训练标记量5000亿），其性能与缩放预测及现有模型对比验证了研究结论。SODA可作为多样化音频/文本任务的灵活基础架构——我们通过在同一统一架构上微调实现音色保持的语音到语音翻译，展示了其应用潜力。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
当前音频语言模型存在两类主要局限：
- **以LLM为中心**：在预训练文本大模型上添加音频模块，导致“语义瓶颈”，无法进行高保真的音频到音频建模。
- **纯语义模型**：仅使用语义音频标记，丢弃了关键的声学细节，限制了音频的高保真理解和生成能力。同时，现有的原生音频模型多专注于特定任务，缺乏与文本的联合建模。

2)  
论文提出了SODA模型，通过一个统一的、基于下一个标记预测的框架，联合建模语义、声学和文本标记，以解决上述问题。其核心方法包括：
- **标记设计与交错**：使用Mimi神经编解码器将音频离散化为标记，其中第一个码本捕获语义内容，其余码本捕获声学细节。在话语级别将音频标记与对应文本标记交错排列，避免了词级对齐错误，并支持音频优先或文本优先的格式。这种设计使单个模型能够学习音频续写、文本续写、音频到文本和文本到音频四种能力。
- **系统化的训练方案研究**：通过实证研究确定了关键设计选择：
    - **数据源**：结合Yodas和Emilia语音语料库，以平衡语义、声学和跨模态性能。
    - **文本混合比例**：在预训练数据中加入5%的高质量纯文本数据（Nemotron），显著提升了文本知识能力，且未损害音频性能。
    - **标记组合**：采用“语义+声学+文本”的交错组合，在可接受的语义理解轻微下降的代价下，实现了跨模态能力和高保真音频生成的统一。
- **首个离散音频模型的缩放定律研究**：通过IsoFLOP分析64个模型，发现对于计算最优配置，最优数据量D*的增长速度（∝ C^0.579）快于最优模型大小N*（∝ C^0.367）。这表明音频标记的信息密度低于文本，需要更多数据来有效学习。
- **冷启动训练**：实验表明，从头开始训练（冷启动）在音频任务上优于从预训练文本LLM初始化（热启动），并且训练更稳定。

3)  
SODA模型在一系列任务上展现了作为统一骨干网络的灵活性和竞争力：
- **跨模态任务**：在自动语音识别（ASR）和文本到语音（TTS）任务上取得显著效果，例如，4B参数的SODA在LibriSpeech ASR上词错误率（WER）达到5.0%。
- **音频理解任务**：在声学理解（Salmon基准测试）和语义理解（sBLIMP, sWUGGY）任务上表现稳健。
- **文本知识任务**：随着模型规模扩大，文本知识能力（如HellaSwag）呈现加速增长趋势。
- **新任务适配性**：通过微调，SODA可以轻松适配新的音频到音频任务。论文演示了将其用于语音到语音翻译（S2ST），在保留说话人音色的同时，取得了有竞争力的翻译质量（BLEU分数）和说话人相似度（SIM）。
</div>

</details>

---

## Hardware-accelerated graph neural networks: an alternative approach for neuromorphic event-based audio classification and keyword spotting on SoC FPGA
- **Authors**: Kamil Jeziorek, Piotr Wzorek, Krzysztof Blachut, Hiroshi Nakano, Manon Dampfhoffer, Thomas Mesquida, Hiroaki Nishi, Thomas Dalgaty, Tomasz Kryjak
- **Categories**: cs.LG, cs.AI, cs.SD, eess.AS
- **arXiv**: [https://arxiv.org/abs/2602.16442v1](https://arxiv.org/abs/2602.16442v1)
- **PDF**: [https://arxiv.org/pdf/2602.16442v1](https://arxiv.org/pdf/2602.16442v1)

随着嵌入式边缘传感器记录的数据量不断增长，尤其是来自产生离散事件流的神经形态设备，对硬件感知的神经架构的需求日益迫切，以实现高效、低延迟且节能的本地处理。本文提出了一种用于音频处理的事件图神经网络的FPGA实现方案。我们采用人工耳蜗将时间序列信号转换为稀疏事件数据，从而降低内存和计算成本。该架构在SoC FPGA上实现，并在两个开源数据集上进行了评估。在分类任务中，我们的基线浮点模型在SHD数据集上达到了92.7%的准确率，仅比当前最优水平低2.4%，同时所需参数量减少了10倍以上和67倍。在SSC数据集上，我们的模型取得了66.9%-71.0%的准确率。与基于FPGA的脉冲神经网络相比，我们的量化模型达到了92.3%的准确率，性能最高提升19.3%，同时减少了资源占用和延迟。对于SSC数据集，我们首次报告了硬件加速的评估结果。此外，我们首次实现了事件音频关键词检测的端到端FPGA系统，将图卷积层与循环序列建模相结合。该系统在词尾检测中达到最高95%的准确率，延迟仅为10.53微秒，功耗为1.18瓦，为节能的事件驱动关键词检测建立了强有力的基准。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：随着物联网边缘传感器数据量激增，特别是神经形态设备产生的离散事件流，需要高效、低延迟、低功耗的本地处理硬件。传统方法（如GPU）功耗高，微处理器难以满足实时性要求。  
- **既有方法问题**：  
  - 事件音频处理常采用**脉冲神经网络（SNN）**，但其突触权重访问模式非确定性，难以真正利用事件稀疏性。  
  - 现有FPGA加速方案主要针对SNN，在分类任务中准确率较低（如SHD数据集上最高87.8%），且延迟和资源消耗较高。  

2)  
- **核心方法**：提出一种基于**事件图神经网络（GNN）**的FPGA硬件加速器，用于事件音频分类和关键词检测。  
- **关键优化与解决思路**：  
  - **事件图生成**：  
    - 使用**人工耳蜗**将时间序列信号转换为稀疏事件流，降低计算开销。  
    - 设计**确定性图生成模块**：采用1D上下文内存（BRAM）按通道存储最新事件时间戳，通过“跳跃步长连接”预定义模式建立边，减少内存访问和搜索延迟。  
    - 简化事件特征：用邻域事件的平均时空坐标替代复杂的法向量计算，降低计算复杂度。  
  - **图卷积优化**：  
    - 采用**PointNetConv层**进行消息传递，支持异步事件逐处理。  
    - 引入**位置归一化**：将边向量（通道差、时间差）重新缩放至(0,1)范围，提升训练稳定性和量化精度。  
    - 集成批归一化层（量化时折叠），避免参数量增加。  
  - **硬件感知设计**：  
    - 量化感知训练：权重和特征图使用8位整数，通过DSP和查找表实现高效乘法和缩放。  
    - 模块化流水线：图生成、卷积、池化等模块并行处理，支持事件级流水线，最小化延迟。  
  - **任务特定头部**：  
    - **分类任务**：全局平均池化后接MLP分类器，可部署在FPGA可编程逻辑（PL）或处理系统（PS）。  
    - **关键词检测**：基于时间窗口的图最大池化，结合STEM-MLP和GRU层进行序列建模，实现端到端实时流处理。  

3)  
- **分类任务**：  
  - **SHD数据集**：量化模型准确率达92.3%，较FPGA-SNN方法提升最高19.3%，参数量减少10–67倍，延迟仅8.07μs，功耗0.99W。  
  - **SSC数据集**：首次实现硬件加速评估，SSC-11准确率84.3%，SSC-35达70.9%。  
- **关键词检测任务**：  
  - 首次端到端FPGA实现，词尾检测准确率>95%，延迟10.53μs，功耗1.18W，为事件驱动KWS树立高效基准。  
- **资源效率**：最小模型（tiny）仅用23%逻辑资源和37%内存，达到与SNN方案相当的精度。
</div>

</details>

---

## SELEBI: Percussion-aware Time Stretching via Selective Magnitude Spectrogram Compression by Nonstationary Gabor Transform
- **Authors**: Natsuki Akaishi, Nicki Holighaus, Kohei Yatabe
- **Categories**: eess.AS, cs.SD
- **arXiv**: [https://arxiv.org/abs/2602.16421v1](https://arxiv.org/abs/2602.16421v1)
- **PDF**: [https://arxiv.org/pdf/2602.16421v1](https://arxiv.org/pdf/2602.16421v1)

基于相位声码器的时间拉伸是一种广泛应用的音频信号时域尺度调整技术。然而，传统实现方法存在“打击乐拖尾”问题，这一常见失真会显著降低打击乐成分的音质。我们认为该失真源于时间上被拖尾的幅度谱图与新生成的局部化相位之间存在根本性的时域尺度失配。为解决此问题，我们提出SELEBI算法——一种信号自适应的相位声码器方法，能在保持稳定性和完美重构特性的同时显著减轻打击乐拖尾现象。与依赖启发式处理或成分分离的传统方法不同，本方法采用非平稳Gabor变换，通过动态调整分析窗长度，为包含显著打击乐成分能量的时段分配短时窗，从而直接从时域信号计算出时间局部化的幅度谱图。这一策略确保了幅度与相位在时域结构上更高的一致性。此外，非平稳Gabor变换的完美重构特性保障了稳定、高保真的信号合成，这与以往基于启发式的方法形成鲜明对比。实验结果表明，所提方法能有效缓解打击乐拖尾现象，并产生自然的听觉效果。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：相位声码器是音频时域拉伸的常用技术，但其基于正弦信号模型，不适合处理打击乐成分，导致“打击乐拖尾”伪影，即打击乐成分的时域特性被破坏。
- **既有方法的问题**：现有方法分为两类：A类方法依赖信号分离，会因分离不完美引入伪影；B类方法虽能保持相位一致性，但其幅度谱图在拉伸过程中仍会时域扩散，与局部化的相位信息不匹配，导致打击乐拖尾无法根除。

2)  
- **核心方法**：论文提出SELEBI算法，利用非平稳Gabor变换（NSDGT）自适应调整分析窗长和帧移，直接计算时域局部化的幅度谱图，以解决幅度与相位间的时域尺度失配问题。
- **具体解决方式**：
  - **自适应窗长**：通过打击乐检测（基于谐波-打击乐分离和混合偏导数相位分析）确定打击乐区域，并根据压缩率动态缩短该区域的分析窗长，增强幅度谱图的时域分辨率。
  - **自适应帧移**：在打击乐区域使用更小的帧移以确保覆盖，在非打击乐区域使用标准帧移，并通过线性插值平滑过渡，保证NSDGT的数值稳定性与完美重构特性。
  - **相位生成**：将传统相位声码器的相位传播公式适配到可变帧移的NSDGT框架中，保持相位一致性。
  - **理论保障**：NSDGT的数学框架确保了自适应处理的能量守恒和稳定合成，避免了先前启发式方法（如谱图位移和插值）的能量损失和近似误差。

3)  
- **任务与效果**：在音频时域拉伸任务上，SELEBI在合成信号和真实录音上均进行了评估。
  - **合成信号**：使用相对RMS误差度量，SELEBI（结合PVDR相位生成）在大多数测试信号（如脉冲、瞬态与正弦混合信号）上取得了最低或次低误差，尤其在4倍拉伸时显著减少了打击乐拖尾。
  - **真实录音**：主观听力测试（基于ITU-R BS.2132-0）显示，SELEBI在“整体质量”、“打击乐锐度”和“音调成分清晰度”上均优于对比方法（PV、PVDR、DIALGA等），在4倍拉伸时优势更明显，能更自然地保留打击乐攻击特性且不损害音调成分。
</div>

</details>

---

## Online Single-Channel Audio-Based Sound Speed Estimation for Robust Multi-Channel Audio Control
- **Authors**: Andreas Jonas Fuglsig, Mads Græsbøll Christensen, Jesper Rindom Jensen
- **Categories**: eess.AS, cs.SD
- **arXiv**: [https://arxiv.org/abs/2602.16416v1](https://arxiv.org/abs/2602.16416v1)
- **PDF**: [https://arxiv.org/pdf/2602.16416v1](https://arxiv.org/pdf/2602.16416v1)

鲁棒的空间音频控制依赖于精确的声学传播模型，然而环境变化——尤其是声速的改变——会导致系统性失配，从而降低控制性能。现有方法要么假设声速已知，要么需要多个麦克风，或依赖独立校准，这使其在传感资源有限的系统中难以实际应用。本文提出一种在线声速估计方法，可在常规多通道音频播放过程中运行，且仅需单个观测麦克风。该方法利用声速对重放信号的结构化影响，通过最小化测量音频与参数化声学模型之间的失配来估计声速。仿真结果表明，该方法能准确跟踪不同输入信号下的声速变化，并在声区控制框架中利用估计值补偿传播误差，从而提升空间控制性能。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：稳健的空间音频控制依赖于精确的声学传播模型。然而，环境变化，尤其是声速变化，会引入系统性的延迟和相位失配，严重降低控制性能。  
- **既有方法的问题**：现有方法存在以下局限：  
  - 通常假设声速已知，或需要单独的温湿度传感器进行估计。  
  - 许多方法依赖多个麦克风进行声源定位或校准。  
  - 自适应滤波等方法需要在所有控制点部署麦克风，不适用于传感基础设施有限的系统。  
  - 现有方案通常需要重复校准或大量预测量数据，难以在线适应。

2)  
论文提出了一种在线单通道声速估计方法，其核心是通过最小化测量信号与参数化声学模型之间的失配来直接估计声速。该方法在通用多通道音频播放期间运行，仅需一个观测麦克风。其解决思路具体如下：  

- **利用结构化声学模型**：  
  - 基于SICER模型，该模型描述了声速变化对脉冲响应的影响。已知参考声速下的脉冲响应后，可以通过一个与声速变化比例因子相关的sinc插值矩阵，将脉冲响应映射到新的声速下。  
  - 将此模型扩展到整个音频信号的重放过程，从而建立起声速变化与观测点处预期重放信号之间的参数化关系。  

- **构建并求解优化问题**：  
  - 在每一帧信号中，将观测麦克风实际测量到的信号，与基于当前声速假设通过上述模型预测的信号进行比较。  
  - 通过求解一个单参数的非凸非线性优化问题，寻找能使预测信号与测量信号之间均方误差最小的声速值。这可以通过网格搜索等数值方法在线实现。  

- **集成至鲁棒控制系统**：  
  - 将上述在线估计得到的声速，集成到空间音频控制框架中。  
  - 当估计的声速变化超过设定阈值时，利用SICER模型更新所有控制点对应的脉冲响应，并据此重新计算扬声器控制滤波器，从而补偿传播失配。  
  - 整个流程允许使用自适应搜索范围来提高估计效率和稳定性，且无需改变底层控制架构。

3)  
- **任务**：在线声速跟踪与鲁棒声区控制。  
- **效果**：  
  - **声速跟踪**：在多种输入信号下均能准确跟踪声速变化，包括白噪声、语音和摇滚音乐。自适应搜索范围在信号频谱内容有限时提高了稳定性。  
  - **声区控制性能**：将估计的声速用于补偿声区控制框架中的传播误差后，系统的声学对比度与信号失真功率性能显著提升，接近使用真实声速的性能上限，并大幅优于使用固定滤波器的基准方法。
</div>

</details>

---

## Multi-Channel Replay Speech Detection using Acoustic Maps
- **Authors**: Michael Neri, Tuomas Virtanen
- **Categories**: eess.AS, cs.LG, cs.SD
- **arXiv**: [https://arxiv.org/abs/2602.16399v1](https://arxiv.org/abs/2602.16399v1)
- **PDF**: [https://arxiv.org/pdf/2602.16399v1](https://arxiv.org/pdf/2602.16399v1)

重放攻击仍是自动说话人验证系统的关键安全漏洞，尤其在实时语音助手应用中。本研究提出声学地图作为多通道录音中重放语音检测的新型空间特征表示方法。该方法基于离散方位角与仰角网格的经典波束成形技术，编码了反映人声辐射与扬声器重放之间物理差异的定向能量分布。我们设计了一个轻量级卷积神经网络处理该特征表示，在ReMASC数据集上以约6千可训练参数实现了具有竞争力的性能。实验结果表明，声学地图为跨设备与声学环境的重放攻击检测提供了紧凑且具物理可解释性的特征空间。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：语音助手等自动说话人验证系统易受重放攻击威胁。现有方法多依赖单通道数据，其提取的时频特征易被攻击者伪造。
- **既有问题**：
  - 单通道方法泛化能力差，测试环境变化时性能急剧下降。
  - 缺乏专门利用多通道空间信息的公开数据集与模型，限制了重放检测的进展。

2)  
论文提出了一种基于**声学地图**的空间特征表示方法，并设计了一个轻量级卷积神经网络进行检测，以解决上述问题。

- **核心特征表示——声学地图**：
  - **生成方式**：对多通道录音，在离散的方位角和仰角网格上，通过经典波束成形技术计算每个方向上的能量分布，形成声学地图。
  - **物理原理**：该方法捕捉了声音场的空间分布。真人语音与扬声器重放语音在声辐射模式上存在物理差异，这些差异被编码在声学地图的方向性能量分布中。
  - **优势**：该特征紧凑、可物理解释，且利用了攻击者难以伪造的空间线索。

- **轻量级CNN分类器**：
  - **网络设计**：专门为处理声学地图设计，采用深度可分离卷积以大幅减少参数量。
  - **高效性**：整个网络仅包含约6000个可训练参数，远少于现有方法，在计算资源有限和训练数据不足的场景下更具优势。
  - **功能**：该网络从声学地图中分层提取特征，最终分类输入为真人语音或重放语音。

- **方法总结**：通过将多通道音频转换为反映声源空间特性的声学地图，并结合一个参数量极小的CNN，该方法在利用空间物理差异进行检测的同时，实现了性能与计算成本的良好平衡。

3)  
- **任务**：在公开的多通道重放攻击数据集ReMASC上，进行重放语音检测。
- **效果**：
  - 在环境依赖（训练与测试环境相同）的设置下，该方法取得了有竞争力的性能，尤其在麦克风数量较多的阵列上表现更好。
  - 其参数量（约6k）远低于基线模型（如M-ALRAD的300k），实现了性能与模型复杂度的良好权衡。
  - 在环境独立（测试环境在训练中未出现）的更具挑战性设置下，性能会下降，这表明当前方法对未知声学环境的泛化能力有限，是其主要的局限性。
</div>

</details>

---

## How to Label Resynthesized Audio: The Dual Role of Neural Audio Codecs in Audio Deepfake Detection
- **Authors**: Yixuan Xiao, Florian Lux, Alejandro Pérez-González-de-Martos, Ngoc Thang Vu
- **Categories**: cs.SD, cs.LG
- **arXiv**: [https://arxiv.org/abs/2602.16343v1](https://arxiv.org/abs/2602.16343v1)
- **PDF**: [https://arxiv.org/pdf/2602.16343v1](https://arxiv.org/pdf/2602.16343v1)

由于文本转语音系统通常不直接生成波形，近期语音伪造检测研究常使用声码器和神经音频编解码器重合成的波形来模拟攻击者。与专为语音合成设计的声码器不同，神经音频编解码器最初是为音频存储与传输压缩而开发的。然而，其离散化语音的能力也引发了基于语言建模的语音合成研究兴趣。鉴于这种双重功能，编解码器重合成的数据可能被标注为真实语音或伪造语音。目前，针对此问题的研究尚少。本研究为此构建了一个具有挑战性的ASVspoof 5数据集扩展版本，探究不同标注选择对检测性能的影响，并为标注策略提供见解。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：音频深度伪造检测面临新挑战。神经音频编解码器（NACs）具有双重用途：既用于音频压缩传输（产生重合成真实音频，CoRS），也用于基于语言模型的语音合成（产生伪造音频，CoSG）。  
- **既有问题**：现有研究很少探讨如何标注CoRS数据。若将其标注为真实，检测器可能无法识别使用同一NAC的CoSG伪造音频；若标注为伪造，检测器可能将编解码器伪影误判为伪造，导致真实音频被错误拒绝。目前缺乏相关数据集支持系统研究。

2)  
- **核心方法**：本文构建了一个名为CodecDeepfakeDetection（CDD）的挑战性数据集，基于ASVspoof 5协议扩展，包含多种NAC和TTS系统生成的音频。通过系统实验，探究了在训练中将CoRS标注为“真实”或“伪造”对检测性能的影响。  
- **解决思路**：  
  - **数据集设计**：CDD包含真实音频、CoRS音频及CoSG伪造音频，覆盖了EnCodec、Mimi、DAC、XCodec2等多种NAC，以及Llasa、MARS5、CSM等TTS系统，确保了数据多样性和挑战性。  
  - **实验设置**：使用X-AASIST和LWBN作为检测器，在训练中分别将CoRS作为真实数据增强或伪造数据增强，评估在不同测试集（T-CoSG、T-CoRS、All）上的性能变化。  
  - **关键发现**：  
    - **NAC设计目标至关重要**：对于以压缩为目标的NAC（如DAC），将CoRS标注为伪造会导致检测器将真实音频判为伪造，性能下降；而将其标注为真实有助于学习编解码器不变特征，提升对CoSG的检测。  
    - **合成导向的NAC**（如Mimi）则相反：将CoRS标注为伪造能更好地利用编解码器特定伪影，提升检测效果。  
    - **数据标注策略需权衡**：最佳标注策略取决于NAC的用途倾向，需避免编解码器伪影与伪造性的错误关联。

3)  
- **任务与效果**：在CodecDeepfakeDetection数据集上评估音频深度伪造检测任务。  
  - **基线模型**（无CoRS增强）在完整测试集上EER约为20%，表明代码基攻击具有挑战性。  
  - **采用CoRS作为真实增强**时，对部分已见NAC（如EnCodec、Mimi、DAC）的T-CoRS子集EER显著降低（降幅达5%-10%），但对合成导向NAC（如Mimi）可能损害相关TTS攻击的检测。  
  - **采用CoRS作为伪造增强**时，可能强化编解码器伪影与伪造的关联，导致真实音频得分下降，尤其对高保真NAC（如DAC）负面影响较大。  
  - **总体**：研究为不同NAC提供了数据标注策略的实证依据，有助于提升检测器在代码基攻击场景下的鲁棒性。
</div>

</details>

---

## Spatial Audio Question Answering and Reasoning on Dynamic Source Movements
- **Authors**: Arvind Krishna Sridhar, Yinyi Guo, Erik Visser
- **Categories**: cs.SD, cs.AI
- **arXiv**: [https://arxiv.org/abs/2602.16334v1](https://arxiv.org/abs/2602.16334v1)
- **PDF**: [https://arxiv.org/pdf/2602.16334v1](https://arxiv.org/pdf/2602.16334v1)

空间音频理解旨在使机器能够解析复杂的听觉场景，尤其在声源随时间移动的情况下。本研究聚焦于动态推理的空间音频问答任务，要求模型直接从立体声音频中推断物体的运动轨迹、位置及方向变化。首先，我们提出一种以运动为核心的空间音频增强框架，能够从单声道孤立音频事件中合成多样化运动模式，实现可控且可扩展的训练数据生成。其次，我们设计了一种端到端多模态微调方法，引入“思考模式”使音频-语言模型在输出答案前生成显式的中间推理步骤。第三，我们探究了查询条件声源分离作为预处理阶段的影响，并比较了三种推理机制：无掩蔽、音频定位模型和真实掩蔽。实验结果表明，推理过程能增强声源分离的效益，当问题中仅存在单一事件时，思考模式可带来+5.1%的显著性能提升。这些发现揭示了运动建模、推理能力与分离质量之间的相互作用，为推进空间音频理解研究提供了新思路。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：空间音频问答旨在让机器理解包含移动声源的复杂听觉场景。现有方法（如BAT）主要处理静态声源，不支持开放式问答和动态运动推理，且缺乏中间推理步骤，限制了其在真实动态环境中的应用能力。  
- **既有问题**：现有模型无法对声源运动、位置和方向变化进行细粒度时序推理，也未整合查询相关的声源分离来降低音频复杂性，导致在动态多声源场景中性能受限。

2)  
论文通过三个核心方法系统性地解决了上述问题：  
- **运动中心的空间音频数据增强**：  
  - 从AudioSet中提取高质量单声道音频事件，并基于CLAP分数进行过滤。  
  - 为每个事件分配预定义的运动轨迹（如接近、远离、横向移动、弧形运动），使用Pyroomacoustics将其空间化为立体声音频场景。  
  - 基于详细元数据，利用大语言模型自动生成涵盖轨迹、径向变化、比较诊断、时序等七类问题的多样化问答对，支持布尔、多选和开放式格式。  

- **端到端多模态微调与“思考模式”**：  
  - 模型包含时序感知的空间音频编码器、Q-Former投影模块和具备思考能力的大语言模型（Qwen 3 4B）。  
  - “思考模式”要求模型在生成最终答案前，先输出显式的中间推理步骤，增强了可解释性。  
  - 采用两阶段训练策略：先冻结编码器学习音频-文本映射，再联合微调所有组件，并引入批次平衡策略以处理事件重叠场景，保持模型稳定性。  

- **查询条件声源分离**：  
  - 在推理阶段，利用音频接地模型（AGM）根据问题中的关键词检测并提取相关音频事件的时间边界。  
  - 通过时间掩码（将非相关时间段置零）隔离查询相关声源，与“思考模式”协同工作，使模型注意力更集中于关键证据。  
  - 对比了无掩码、AGM掩码和真实掩码三种推理机制，证明高质量分离能显著提升推理效果。

3)  
论文在自建的空间音频问答基准上评估模型，主要效果如下：  
- **整体性能**：在思考模式下，使用真实掩码达到最高准确率56.1%，AGM掩码为55.0%，均优于无掩码基线（54.3%）。思考模式结合声源分离带来显著提升，例如在单事件问题上准确率提升达+5.1%。  
- **任务细分**：  
  - 在“是/否”问题上，真实掩码+思考模式提升最明显（+4.5%）。  
  - 模型在声源轨迹、径向变化、相对运动等动态推理任务上表现良好，尤其在非重叠事件场景中优势显著。  
- **错误分析**：思考模式结合掩码有效减少了方位判断、距离估计等关键错误类别，并大幅降低了答案与推理依据不匹配的情况。
</div>

</details>

---

## BAT: Better Audio Transformer Guided by Convex Gated Probing
- **Authors**: Houtan Ghaffari, Lukas Rauch, Christoph Scholz, Paul Devos
- **Categories**: cs.SD, cs.LG
- **arXiv**: [https://arxiv.org/abs/2602.16305v1](https://arxiv.org/abs/2602.16305v1)
- **PDF**: [https://arxiv.org/pdf/2602.16305v1](https://arxiv.org/pdf/2602.16305v1)

在计算机视觉领域，探针方法被广泛用于忠实评估自监督学习（SSL）嵌入的质量，因为微调可能无法准确反映其内在特性。然而，音频SSL模型仍依赖微调，因为简单的探针方法无法充分释放其潜力，且在AudioSet等基准上竞争最优性能时会改变模型排名。因此，需要一种鲁棒且高效的探针机制来引导音频SSL向可靠、可复现的方法发展。本文提出凸门控探针（CGP），这是一种基于原型的方法，显著缩小了音频领域中微调与探针之间的性能差距。CGP通过门控机制高效利用所有冻结层，并揭示潜在任务相关信息的分布位置。在CGP的指导下，我们重新设计了当前最优音频模型的整个SSL流程，这些模型原本采用了早期SSL方法的传统实现。通过改进数据预处理、模型架构和预训练策略，我们提出了更优音频变换器（BAT），并在音频基准测试中取得了新的最优性能。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：音频自监督学习（SSL）模型在AudioSet等基准上的评估严重依赖微调，而非像计算机视觉领域那样使用冻结特征的探测方法。  
- **既有问题**：  
  - 微调引入超参数敏感性等混杂变量，可能掩盖SSL表示的真实质量，导致结果不可靠且难以复现。  
  - 简单的线性探测无法充分释放音频嵌入的潜力，造成性能差距，从而错误地依赖微调来竞争SOTA。  
  - 当前SOTA模型（如EAT、SSLAM）基于遗留代码实现，存在未记录的架构细节和优化实践，损害了可复现性。

2)  
论文通过提出**Convex Gated Probing（CGP）** 和基于其指导构建的**Better Audio Transformer（BAT）** 来解决上述问题：  
- **CGP方法**：  
  - 采用基于原型的探测机制，通过可学习的软门控向量对冻结主干的所有层嵌入进行加权聚合，生成单一表示。  
  - 将聚合后的表示与K个原型计算余弦相似度，并对块标记的相似度进行最小-最大池化，再与CLS标记的相似度拼接，最终输入线性分类器。  
  - 这种方法能高效利用所有层，暴露任务相关信息的潜在位置，显著缩小冻结探测与微调之间的性能差距。  
- **BAT的改进**：在CGP的指导下，系统优化了音频SSL流程：  
  - **数据预处理**：使用现代Mel频谱图提取方法，结合分贝尺度对数压缩和局部最小-最大归一化，避免依赖全局统计量，提升鲁棒性。  
  - **目标生成**：在多头自注意力（MHSA）中引入门控机制，抑制注意力沉没点，并利用块末端输出作为SSL目标，提升语义质量。  
  - **模型架构**：将轻量CNN解码器替换为更强大的ViT解码器，使编码器深层能专注于高级语义而非低级重建，改善嵌入的线性可分性。  
  - **训练配方**：去除遗留的大损失缩放因子，使用简化的目标函数，增强优化稳定性和可复现性。

3)  
在多个音频基准任务上，BAT取得了SOTA或具有竞争力的效果：  
- **AudioSet**：在AS-20k和AS-2M上，BAT的微调性能（mAP 41.32/48.55）超越复现的基线模型；其CGP冻结探测性能（mAP 37.52/42.90）显著高于EAT和SSLAM，且接近微调结果。  
- **ESC-50**：BAT的CGP性能（95.80%）甚至超过微调结果，显示其冻结嵌入的高质量。  
- **Speech Commands V2**：BAT在微调和CGP设置下均达到最佳性能（98.13%/97.13%）。  
- **总体**：BAT在冻结特征评估中大幅领先基线，证明了CGP的有效性，并为音频SSL提供了更可靠、可复现的评估框架。
</div>

</details>

---

## Color-based Emotion Representation for Speech Emotion Recognition
- **Authors**: Ryotaro Nagase, Ryoichi Takashima, Yoichi Yamashita
- **Categories**: eess.AS, cs.AI, cs.SD
- **arXiv**: [https://arxiv.org/abs/2602.16256v1](https://arxiv.org/abs/2602.16256v1)
- **PDF**: [https://arxiv.org/pdf/2602.16256v1](https://arxiv.org/pdf/2602.16256v1)

传统语音情感识别通常依赖分类或维度标签，但这类方法在情感多样性与可解释性表征方面存在局限。为突破此限制，本研究聚焦于色调、饱和度、明度等色彩属性，将情感表征为连续且可解释的数值。通过众包方式对情感语音语料库进行色彩属性标注并开展分析。在此基础上，采用机器学习与深度学习技术构建了面向语音情感识别的色彩属性回归模型，并探索了色彩属性回归与情感分类的多任务学习方法。实验结果表明：语音情感与色彩属性之间存在显著关联，所构建的色彩属性回归模型在语音情感识别任务中表现良好，且多任务学习策略有效提升了各项任务的性能。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：语音情感识别（SER）传统上依赖分类（如快乐、愤怒）或维度（如效价、唤醒度）标签。  
- **既有方法问题**：  
  - 分类方法无法描述混合或模糊情感，受限于预定义类别。  
  - 维度方法虽能捕捉细微差异，但解释性差，常需专业知识。  
  - 两者均难以同时兼顾情感多样性与直观理解。

2)  
- **核心方法**：提出基于颜色属性（色调、饱和度、明度）的SER框架，将情感表示为连续且可解释的数值。  
- **解决思路**：  
  - **数据标注**：通过众包为日语情感语音数据集（JVNV）添加颜色属性标签，分析其与分类情感的关系（如快乐对应黄色调，愤怒对应红色调）。  
  - **回归模型**：使用支持向量回归（SVR）和深度神经网络（DNN）直接从语音预测颜色属性。  
    - 采用HuBERT等自监督学习特征提升回归效果。  
    - 针对色调的周期性，使用正弦/余弦分量进行建模。  
  - **多任务学习**：联合训练颜色属性回归与六分类情感分类，通过加权损失函数（CCC损失 + 交叉熵）使两者相互促进。  
- **优势**：颜色属性兼具直观性（视觉对应）与连续性，能更灵活地表征混合情感，且无需复杂解释。

3)  
- **任务与效果**：  
  - **颜色属性回归**：在JVNV数据集上，SVR与DNN模型均能有效预测色调（最小角误差31.3°）、饱和度（CCC最高0.533）和明度（CCC最高0.794）。  
  - **多任务学习**：联合训练显著提升性能——在α=0.9时，分类准确率达90.8%（较单任务提升2.5%），同时回归任务的CCC也同步提高。  
  - **应用价值**：为情感可视化（如咨询、在线教育）提供了可解释的连续表示。
</div>

</details>

---

## How Much Does Machine Identity Matter in Anomalous Sound Detection at Test Time?
- **Authors**: Kevin Wilkinghoff, Keisuke Imoto, Zheng-Hua Tan
- **Categories**: eess.AS, cs.SD
- **arXiv**: [https://arxiv.org/abs/2602.16253v1](https://arxiv.org/abs/2602.16253v1)
- **PDF**: [https://arxiv.org/pdf/2602.16253v1](https://arxiv.org/pdf/2602.16253v1)

异常声音检测（ASD）基准测试通常假设测试时被监测机器的身份已知，且录音按机器分别评估。然而，在实际多台已知机器同时运行的监测场景中，测试录音可能无法可靠归属到特定机器，而要求机器身份会带来部署限制，例如每台机器需配备专用传感器。为揭示在标准分机器评估下被掩盖的性能下降及方法间鲁棒性差异，我们提出对ASD评估协议进行最小修改：将多台机器的测试录音合并，在推理时不依赖机器身份进行联合评估。训练数据和评估指标保持不变，机器身份标签仅用于事后评估。对代表性ASD方法的实验表明，放宽这一假设会暴露出标准分机器评估所隐藏的性能下降与方法特异性鲁棒性差异，且这些性能下降与隐式机器识别准确度密切相关。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：异常声音检测（ASD）在机器状态监测中广泛应用，当前主流基准（如DCASE挑战赛）默认一个关键假设：测试时已知被监测机器的身份，并按机器分别评估。  
- **既有方法的问题**：这一假设在实际多机器并发监控场景中往往不成立，因为测试录音可能无法可靠归属到特定机器。现有许多方法依赖机器特定模型、统计信息或延迟聚合，这些设计在机器身份未知时会导致性能下降，而标准评估协议掩盖了这种鲁棒性差异。

2)  
- **核心方法**：论文未提出新检测模型，而是设计了一个**最小化修改的评估协议**，以分析现有ASD方法在机器身份未知时的表现。该协议仅放松“测试时已知机器身份”这一假设，其他所有设置（训练数据、评估指标）保持不变。  
- **具体实施**：  
  - **测试集构建**：将来自多个已知机器的所有测试录音合并为一个混合测试集，在推断时不提供机器身份信息。  
  - **任务定义**：主要任务仍是异常检测，系统需为每个录音输出异常分数；附加一个**隐式机器身份识别**的辅助任务，通过事后分析评估模型能否从异常分数中正确推断机器身份。  
  - **理论关联**：论文形式化地证明了，当机器身份未知时，异常检测性能的下降直接源于隐式机器识别的错误。例如，采用最小化机器特定异常分数的聚合策略时，性能优劣取决于能否正确选择对应机器的正态模型。  
- **解决思路**：通过该协议，可以：  
  - 暴露不同ASD方法在机器身份缺失时的鲁棒性差异；  
  - 将异常检测性能下降与隐式机器识别准确率定量关联，从而解释“机器身份为何重要”及“何时重要”。

3)  
- **评估任务**：在DCASE2020至2025的多个公开ASD数据集上，测试了包括判别式训练模型、基于预训练嵌入的无训练方法、机器特定模型在内的代表性方法。  
- **取得的效果**：  
  - 所有方法在机器身份未知时均出现性能下降，但下降幅度因方法类型而异：**判别式训练模型**鲁棒性最强，性能下降最小；**无训练嵌入方法**和**机器特定模型**下降显著。  
  - 揭示了**异常检测性能退化与隐式机器识别准确率之间的强相关**，验证了理论预测。  
  - 发现某些异常分数归一化策略（如LDN）虽降低识别准确率，却能提升绝对检测性能，说明鲁棒性不仅取决于识别能力，还与分数聚合方式有关。
</div>

</details>

---

## Real time fault detection in 3D printers using Convolutional Neural Networks and acoustic signals
- **Authors**: Muhammad Fasih Waheed, Shonda Bernadin
- **Categories**: eess.SP, cs.SD, eess.AS
- **arXiv**: [https://arxiv.org/abs/2602.16118v1](https://arxiv.org/abs/2602.16118v1)
- **PDF**: [https://arxiv.org/pdf/2602.16118v1](https://arxiv.org/pdf/2602.16118v1)

三维打印过程的可靠性与质量，关键在于能否及时检测出机械故障。传统监测方法多依赖视觉检查与硬件传感器，不仅成本较高，且监测范围有限。本文研究一种可扩展的非接触式方法，通过实时音频信号分析来检测三维打印机中的机械故障。通过采集并分类打印过程中的声发射信号，我们旨在识别喷嘴堵塞、线材断裂、皮带打滑等多种常见机械故障。利用卷积神经网络，我们实现了能够实时进行音频分类的算法，以快速检测上述故障。研究方法包括开展一系列受控实验以收集音频数据，随后应用先进的机器学习模型进行故障检测。此外，本文综述了制造业与三维打印领域中基于音频的故障检测相关文献，从而将本研究置于更广泛的学术背景中。初步结果表明，结合机器学习技术分析音频信号，能够为增强实时故障检测提供可靠且经济高效的途径。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：3D打印的可靠性与质量高度依赖对机械故障的及时检测。  
- **既有方法问题**：  
  - **传统方法**（如人工视觉检查、硬件接触式传感器）成本高、监测范围有限、无法实时连续监控，且易受主观因素和环境干扰。  
  - **摄像头方案**存在视野局限或多系统成本高、实施复杂、对光照敏感等问题。  

2)  
- **核心方法**：提出一种基于**声学信号**与**卷积神经网络（CNN）** 的非接触式实时故障检测方法。  
- **关键步骤**：  
  - **数据采集与预处理**：使用麦克风采集3D打印机挤出机在正常与故障状态下的声音，并通过**带通滤波（100–1200 Hz）** 和**减法降噪**技术滤除环境噪声。  
  - **特征提取**：将音频信号转换为**声谱图**（时频表示），作为CNN的输入图像。  
  - **模型构建与训练**：采用**CNN模型**（结合迁移学习）对声谱图进行分类，以识别喷嘴堵塞、线材断裂、皮带打滑等故障的独特声学特征。  
  - **实时监测**：系统持续分析打印过程中的声学信号，实现故障的即时检测与预警。  
- **方法优势**：  
  - **非侵入且成本低**：仅需廉价麦克风，无需改造打印机硬件。  
  - **高精度与可扩展性**：CNN能有效提取声谱图中的细微模式，提升检测准确性；方法易于适配不同故障类型与打印机型号。  

3)  
- **任务与效果**：  
  - **任务**：针对3D打印过程中的机械故障（如喷嘴堵塞、线材断裂、皮带打滑）进行实时检测。  
  - **效果**：在包含256个音频样本的数据集上，模型达到约**91%的准确率、88%的精确率、85%的召回率**，综合F1分数为86.5%。  
  - **对比优势**：优于传统振动传感器方法（准确率75–85%），实现了**非接触、低成本、高精度的实时监测**，为工业环境中的预测性维护提供了可行方案。
</div>

</details>

---
