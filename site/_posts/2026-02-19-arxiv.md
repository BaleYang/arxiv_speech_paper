---
layout: post
title: "arXiv Daily – 2026-02-19"
tags: [arxiv, cs.SD, eess.AS]
---

以下为 2026-02-19（CST，北京时间）窗口内更新的论文中文译文：
- 时间窗口（锚点 08:50 CST）：2026-02-18 08:50 — 2026-02-19 08:50
- 抓取总数：11 篇 | 本页显示：11 篇（去重/过滤后）

## Scaling Open Discrete Audio Foundation Models with Interleaved Semantic, Acoustic, and Text Tokens
- **Authors**: Potsawee Manakul, Woody Haosheng Gan, Martijn Bartelds, Guangzhi Sun, William Held, Diyi Yang
- **Categories**: cs.SD, cs.CL, eess.AS
- **arXiv**: [https://arxiv.org/abs/2602.16687v1](https://arxiv.org/abs/2602.16687v1)
- **PDF**: [https://arxiv.org/pdf/2602.16687v1](https://arxiv.org/pdf/2602.16687v1)

当前音频语言模型主要采用文本优先策略，要么基于预训练文本大语言模型扩展，要么仅依赖语义音频标记，这限制了通用音频建模能力。本文通过系统性实证研究，提出原生音频基础模型，该模型通过大规模音频的下一标记预测，联合建模语义内容、声学细节与文本信息，以支持通用音频生成与跨模态能力。我们为构建此类模型提供了全面的实证洞见：（1）系统探究了数据来源、文本混合比例与标记组合等设计选择，建立了经过验证的训练方案；（2）通过对64个模型（计算量覆盖$3{\times}10^{18}$至$3{\times}10^{20}$ FLOPs）进行等计算量分析，首次开展离散音频模型的缩放规律研究，发现最优数据增长速度比最优模型规模快1.6倍；（3）基于上述发现训练了SODA模型系列（参数规模1.35亿至40亿，训练标记量5000亿），其性能与缩放预测及现有模型对比验证了方法的有效性。SODA可作为多样化音频/文本任务的灵活基础架构——我们通过在同一统一架构上微调实现音色保持的语音到语音翻译任务，展示了其应用潜力。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
当前音频语言模型存在两类主要局限：
- **以LLM为中心**：在预训练文本大模型上扩展音频模块，导致“语义瓶颈”，无法进行高保真的音频到音频建模。
- **纯语义模型**：仅使用语义音频标记，丢弃了关键的声学细节，限制了高保真理解和生成能力。
- **原生音频模型**：直接建模声学标记，但通常专注于特定任务且缺乏文本集成，无法实现统一的多模态能力。

2)  
论文提出了SODA，一个基于统一的下一个标记预测框架的原生音频基础模型，通过系统性的实证研究解决了上述问题：
- **统一建模**：在**话语级别**交错编码**语义、声学和文本标记**，使单一模型能够联合学习音频内容、声学细节和文本信息，支持音频理解、生成和跨模态任务。
- **优化的训练方案**：通过消融实验确定了关键设计选择：
  - **数据源**：结合Yodas和Emilia语音语料库，平衡多样性与质量。
  - **文本混合比例**：加入5%的高质量纯文本数据（Nemotron），显著提升文本知识且不损害音频性能。
  - **标记组合**：采用“语义+声学+文本”的交错格式，在可接受的语义理解折衷下，解锁了跨模态（如ASR、TTS）和文本能力。
- **首个离散音频模型的缩放定律研究**：
  - 通过64个IsoFLOP模型的分析，发现最优数据规模增长快于最优模型规模（D* ∝ C^0.579，N* ∝ C^0.367），这与音频标记信息密度较低的特性一致。
  - 验证了验证损失（NLL）是下游任务性能的可靠预测指标。
- **训练策略**：实验表明，**冷启动**（随机初始化）在音频任务上优于从预训练文本LLM**热启动**，且训练更稳定。

3)  
SODA模型在多个任务上展现了竞争性效果，验证了其作为统一骨干的灵活性：
- **跨模态任务**：在ASR（LibriSpeech）和TTS（seed-tts-eval）上表现优异，例如4B参数模型达到5.0%的ASR词错误率和6.1%的TTS词错误率。
- **音频理解**：在声学理解任务（Salmon）上达到约70%的准确率，在语义理解任务（sWUGGY）上达到61.8%。
- **文本知识**：在文本基准（如HellaSwag）上显示出明显的涌现能力，4B模型准确率达到52.6%。
- **新任务适配性**：通过微调，将**语音到语音翻译**（S2ST）轻松表述为下一个标记预测任务，在CVSS-T数据集上取得了良好的翻译质量（BLEU）和说话人相似度（SIM），证明了其作为灵活骨干的潜力。
</div>

</details>

---

## Hardware-accelerated graph neural networks: an alternative approach for neuromorphic event-based audio classification and keyword spotting on SoC FPGA
- **Authors**: Kamil Jeziorek, Piotr Wzorek, Krzysztof Blachut, Hiroshi Nakano, Manon Dampfhoffer, Thomas Mesquida, Hiroaki Nishi, Thomas Dalgaty, Tomasz Kryjak
- **Categories**: cs.LG, cs.AI, cs.SD, eess.AS
- **arXiv**: [https://arxiv.org/abs/2602.16442v1](https://arxiv.org/abs/2602.16442v1)
- **PDF**: [https://arxiv.org/pdf/2602.16442v1](https://arxiv.org/pdf/2602.16442v1)

随着嵌入式边缘传感器采集数据量的增长，尤其是神经形态设备产生的离散事件流，对硬件感知型神经架构的需求日益迫切，以实现高效、低延迟且节能的本地处理。本文提出一种面向音频处理的事件图神经网络FPGA实现方案。我们采用人工耳蜗将时序信号转换为稀疏事件数据，从而降低内存与计算开销。该架构在SoC FPGA上实现，并在两个开源数据集上进行了评估。在分类任务中，我们的基线浮点模型在SHD数据集上达到92.7%的准确率，仅比当前最优水平低2.4%，而参数量减少了超过10倍和67倍。在SSC数据集上，模型准确率达到66.9%-71.0%。与基于FPGA的脉冲神经网络相比，我们的量化模型取得92.3%的准确率，最高超出前者19.3%，同时降低了资源占用和延迟。针对SSC数据集，我们首次报告了硬件加速评估结果。此外，我们首次实现了端到端的FPGA事件音频关键词检测系统，将图卷积层与循环序列建模相结合。该系统词尾检测准确率最高达95%，延迟仅10.53微秒，功耗1.18瓦，为节能型事件驱动关键词检测建立了强有力的基准。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：随着物联网边缘传感器数据量激增，特别是神经形态设备产生的离散事件流，需要高效、低延迟、低功耗的本地处理硬件。  
- **既有方法问题**：  
  - 传统GPU功耗高，微处理器难以满足延迟要求。  
  - 事件音频处理常用脉冲神经网络（SNN），但其突触权重访问模式非确定性，难以真正利用事件稀疏性。  
  - 现有FPGA加速方案多针对计算机视觉，缺乏针对时间序列音频的专用硬件架构。  

2)  
- **核心方法**：提出基于SoC FPGA的硬件加速事件图神经网络（GNN），用于事件音频分类和关键词检测。  
- **解决方案**：  
  - **数据表示**：使用人工耳蜗将时间序列信号转换为稀疏事件数据，构建动态更新的谱时事件图。  
  - **图生成优化**：  
    - 采用“跳跃步连接”确定性模式生成边，减少内存和计算开销。  
    - 用1D上下文内存（BRAM）按通道存储最新事件时间戳，简化邻域搜索。  
    - 用平均时间/通道坐标替代复杂法向量特征，降低计算成本。  
  - **图卷积改进**：  
    - 在PointNetConv层中集成批归一化（训练时使用，硬件部署时折叠）。  
    - 添加位置归一化，将边向量缩放到(0,1)范围，提升训练稳定性和量化精度。  
  - **硬件设计**：  
    - 支持全异步事件逐处理，保持数据时间稀疏性。  
    - 量化感知训练，使用整数乘法和查找表实现低精度计算。  
    - 模块化设计，可调整并行乘法单元数量以平衡资源与延迟。  
  - **任务适配**：  
    - **分类任务**：使用图平均池化聚合事件特征，后接多层感知机分类头。  
    - **关键词检测**：将事件流分时窗，用图最大池化聚合特征，结合STEM-MLP和GRU进行序列建模，实时输出检测结果。  

3)  
- **分类任务**：  
  - 在SHD数据集上，量化模型准确率达92.3%，仅比浮点最优模型低2.4%，参数量减少10倍至67倍。相比FPGA SNN方案，准确率最高提升19.3%，资源使用和延迟更低。  
  - 在SSC数据集上首次实现硬件加速评估，准确率达66.9–71.0%。  
- **关键词检测任务**：  
  - 首次实现端到端FPGA事件音频关键词检测系统，词尾检测准确率最高达95%，延迟仅10.53 µs，功耗1.18 W，为高效事件驱动KWS树立强基准。
</div>

</details>

---

## SELEBI: Percussion-aware Time Stretching via Selective Magnitude Spectrogram Compression by Nonstationary Gabor Transform
- **Authors**: Natsuki Akaishi, Nicki Holighaus, Kohei Yatabe
- **Categories**: eess.AS, cs.SD
- **arXiv**: [https://arxiv.org/abs/2602.16421v1](https://arxiv.org/abs/2602.16421v1)
- **PDF**: [https://arxiv.org/pdf/2602.16421v1](https://arxiv.org/pdf/2602.16421v1)

基于相位声码器的时间拉伸是一种广泛应用的音频信号时域尺度调整技术。然而，传统实现方法存在“打击乐拖尾”问题，这一常见伪影会显著降低打击乐成分的音质。我们认为该伪影源于时间上被拖尾的幅度谱图与新生成的局部化相位之间存在根本性的时域尺度失配。为解决此问题，我们提出SELEBI算法——一种信号自适应的相位声码器方法，能在保持算法稳定性与完美重构特性的同时，显著减轻打击乐拖尾现象。与依赖启发式处理或成分分离的传统方法不同，本方法采用非平稳Gabor变换，通过动态调整分析窗长度，对包含显著打击乐成分能量的区间分配短时窗，从而直接从时域信号计算出时间局部化的幅度谱图。该方法确保了幅度与相位在时域结构上更高的一致性。此外，非平稳Gabor变换的完美重构特性保障了稳定、高保真的信号合成，这与以往启发式方法形成鲜明对比。实验结果表明，所提方法能有效抑制打击乐拖尾现象，并产生自然的音质。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：相位声码器是音频时域拉伸的常用技术，但其基于正弦信号模型，不适合处理打击乐成分，导致“打击乐拖尾”伪影，即打击乐成分的时域特性被破坏。
- **既有方法的问题**：现有方法分为两类：A类方法依赖信号分离，会因分离不完美引入伪影；B类方法虽能保持相位一致性，但其幅度谱图在拉伸过程中仍会时域扩散，与局部化的相位信息不匹配，导致打击乐拖尾无法根除。

2)  
- **核心方法**：论文提出SELEBI算法，利用非平稳Gabor变换（NSDGT）自适应调整分析窗长和帧移，直接计算时域局部化的幅度谱图，以解决幅度与相位间的时域尺度不匹配问题。
- **具体解决方式**：
  - **自适应窗长**：通过打击乐检测（基于谐波-打击乐分离和混合相位导数）确定打击乐事件的位置和强度（压缩率），在打击乐区域使用短窗以提升时域分辨率，在非打击乐区域使用长窗以保持频率分辨率，并通过线性过渡避免突变。
  - **自适应帧移**：在打击乐区域减小帧移以确保足够的重叠和稳定性，在非打击乐区域使用标准帧移，并通过线性插值平滑过渡。
  - **相位生成**：适配可变帧移的相位生成公式（如相位导数计算和传播），保持与NSDGT的兼容性。
  - **数学保证**：NSDGT的完美重构性质确保了信号合成的高保真度和稳定性，避免了启发式方法（如先前工作中的时频单元平移和插值）带来的能量损失和近似误差。

3)  
- **任务与效果**：在音频时域拉伸任务上，SELEBI在合成信号和真实录音上均进行了评估。
  - **合成信号**：使用相对RMS误差评估，SELEBI（结合PVDR相位生成）在多数信号（如脉冲、瞬态及其与正弦波的混合）上取得了最低或次低误差，尤其在4倍拉伸时显著减少了打击乐拖尾。
  - **真实录音**：通过主观听力测试（基于ITU-R BS.2132-0），SELEBI在“整体质量”、“打击乐清晰度”和“音调成分清晰度”上均优于对比方法（PV、PVDR、DIALGA），尤其在4倍拉伸时优势更明显，能更自然地保持打击乐的尖锐度和音调成分的清晰度。
</div>

</details>

---

## Online Single-Channel Audio-Based Sound Speed Estimation for Robust Multi-Channel Audio Control
- **Authors**: Andreas Jonas Fuglsig, Mads Græsbøll Christensen, Jesper Rindom Jensen
- **Categories**: eess.AS, cs.SD
- **arXiv**: [https://arxiv.org/abs/2602.16416v1](https://arxiv.org/abs/2602.16416v1)
- **PDF**: [https://arxiv.org/pdf/2602.16416v1](https://arxiv.org/pdf/2602.16416v1)

稳健的空间音频控制依赖于精确的声学传播模型，然而环境变化——尤其是声速的改变——会导致系统性失配，从而降低控制性能。现有方法要么假设声速已知，要么需要多个麦克风，或依赖独立校准，这使其在传感资源有限的系统中难以实际应用。本文提出一种在线声速估计方法，可在通用多通道音频播放过程中运行，且仅需单个观测麦克风。该方法利用声速对重放信号的结构化影响，通过最小化测量音频与参数化声学模型之间的失配来估计声速。仿真结果表明，该方法能准确跟踪不同输入信号下的声速变化，并在声场分区控制框架中利用估计值补偿传播误差，从而显著提升空间控制性能。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：稳健的空间音频控制依赖于精确的声学传播模型。实际部署中，环境变化（如温度变化导致声速改变）会引入系统性的延迟和相位失配，严重降低控制性能。  
- **既有方法问题**：现有方法大多假设声速已知、需要多个麦克风进行部署或依赖单独的校准过程。这些要求使得它们在传感资源有限的系统中不切实际，难以在线适应环境变化。

2)  
- **核心思路**：论文提出一种在线单通道声速估计方法。该方法仅需一个观测麦克风，在常规多通道音频播放期间，通过最小化测量信号与参数化声学模型之间的失配来直接估计声速。  
- **关键技术**：  
  - **信号建模**：基于SICER模型，将声速变化对脉冲响应的影响建模为一种压缩/扩展的sinc插值操作。该模型能将参考声速下的已知脉冲响应映射到新声速下。  
  - **在线估计**：利用已知的参考声速下的脉冲响应，构建在当前声速假设下的预期播放信号模型。通过网格搜索，寻找能使模型输出与单麦克风实际测量信号之间均方误差最小的声速值，作为当前帧的估计。  
  - **集成控制**：将估计出的声速用于更新声学模型，进而重新计算空间音频控制滤波器（如声区控制滤波器），以补偿传播失配，而无需改变底层控制架构。  
- **方法优势**：实现了仅用单通道音频信号的在线跟踪，无需额外传感器或中断播放进行专门校准，适用于传感基础设施有限的系统。

3)  
- **评估任务**：在声区控制仿真任务中评估了方法的声速跟踪性能与控制效果。  
- **取得效果**：  
  - **跟踪性能**：对于白噪声、语音和音乐等多种输入信号，该方法能准确跟踪仿真的阶跃式声速变化（从333 m/s到353 m/s）。  
  - **控制性能**：将估计的声速集成到声区控制框架后，其产生的声学对比度和信号失真度性能接近使用真实声速（理论上限）的性能，并显著优于使用固定滤波器的基准方法，有效补偿了因声速变化导致的性能下降。
</div>

</details>

---

## Multi-Channel Replay Speech Detection using Acoustic Maps
- **Authors**: Michael Neri, Tuomas Virtanen
- **Categories**: eess.AS, cs.LG, cs.SD
- **arXiv**: [https://arxiv.org/abs/2602.16399v1](https://arxiv.org/abs/2602.16399v1)
- **PDF**: [https://arxiv.org/pdf/2602.16399v1](https://arxiv.org/pdf/2602.16399v1)

重放攻击仍是自动说话人验证系统的关键安全漏洞，尤其在实时语音助手应用中。本研究提出声学地图作为多通道录音中重放语音检测的新型空间特征表示方法。该方法基于离散方位角与仰角网格的经典波束成形技术构建，通过编码方向性能量分布来捕捉人声辐射与扬声器重放之间的物理差异。我们设计了一个轻量级卷积神经网络处理该特征表示，在ReMASC数据集上以约6千可训练参数实现了具有竞争力的性能。实验结果表明，声学地图为跨设备与声学环境的重放攻击检测提供了紧凑且具物理可解释性的特征空间。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：语音助手等自动说话人验证系统易受重放攻击威胁。现有方法多依赖单通道数据，其提取的时频特征易被攻击者伪造，且泛化能力差，当测试环境声学特性改变时，性能会大幅下降。
- **既有方法问题**：尽管多通道数据蕴含难以伪造的空间线索，但相关研究受限于公开数据集和专门模型的缺乏。现有方法在跨设备和环境时，检测鲁棒性不足。

2)  
论文提出了一种基于**声学地图**的空间特征表示方法，并设计了一个轻量级CNN分类器来解决上述问题。

- **核心特征表示——声学地图**：
    - **生成方式**：对多通道录音，在离散的方位角和仰角网格上，使用经典波束成形技术（如延时求和）计算每个网格点的窄带伪功率响应。
    - **信息编码**：将时频信息在时间和频带上进行平均聚合，形成三维张量。该地图编码了声音的方向性能量分布，能够反映真人发声（复杂声源）与扬声器重放（电声换能器）在物理辐射特性上的根本差异。
    - **优势**：这种表示紧凑且具有物理可解释性，直接捕捉了阵列流形、直达声和早期反射等空间信息，这些信息难以被攻击者轻易模仿。

- **轻量级分类网络**：
    - **架构设计**：一个参数约6k的CNN，专门处理声学地图张量。采用深度可分离卷积块，逐步提取层次化特征，在控制模型容量的同时减少参数量。
    - **高效性**：与需要数百万参数的学习型波束成形器结合分类器的SOTA方法相比，本方法在模型复杂度上极具优势，实现了性能与计算成本的良好权衡。

- **解决思路总结**：通过从物理原理出发构建空间特征（声学地图），替代了易被攻击的单通道时频特征或复杂的端到端学习方案。再配合一个参数极简的定制化CNN，共同应对了特征可伪造性、模型泛化能力弱以及计算资源受限的问题。

3)  
- **任务**：在多通道重放语音检测任务上进行了评估，主要使用ReMASC数据集。
- **效果**：
    - 在**环境相关**设置下，对于麦克风数量较多、空间分辨率较高的阵列（如D3），取得了具有竞争力的检测性能（EER约10.1%），与部分SOTA方法相当。
    - 模型极其轻量（约6k参数），远少于对比的基线模型（30万至100万参数），在性能与效率间取得了良好平衡。
    - 在更具挑战的**环境无关**（泛化至未见环境）设置下，性能会出现下降，这表明固定的频带和静态空间处理对未知环境的适应性有限，但其泛化能力与同类多通道方法水平相当。
</div>

</details>

---

## How to Label Resynthesized Audio: The Dual Role of Neural Audio Codecs in Audio Deepfake Detection
- **Authors**: Yixuan Xiao, Florian Lux, Alejandro Pérez-González-de-Martos, Ngoc Thang Vu
- **Categories**: cs.SD, cs.LG
- **arXiv**: [https://arxiv.org/abs/2602.16343v1](https://arxiv.org/abs/2602.16343v1)
- **PDF**: [https://arxiv.org/pdf/2602.16343v1](https://arxiv.org/pdf/2602.16343v1)

由于文本转语音系统通常不直接生成波形，近期语音伪造检测研究常使用声码器和神经音频编解码器重合成的波形来模拟攻击者。与专为语音合成设计的声码器不同，神经音频编解码器最初是为音频存储与传输压缩而开发的。然而，其离散化语音的能力也引发了基于语言建模的语音合成研究兴趣。鉴于这种双重功能，编解码器重合成的数据可能被标记为真实语音或伪造语音。目前，针对此问题的研究尚少。本研究为此构建了一个具有挑战性的ASVspoof 5数据集扩展版本，探究不同标注选择对检测性能的影响，并为标注策略提供见解。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：音频深度伪造检测面临新挑战。神经音频编解码器（NACs）具有双重用途：既用于音频压缩传输（产生重合成真实音频，CoRS），也用于基于语言模型的语音合成（产生伪造音频，CoSG）。  
- **既有问题**：现有研究很少探讨如何标注CoRS数据。若将其标注为真实，检测器可能无法识别使用同一NAC的CoSG伪造音频；若标注为伪造，检测器可能将编解码器伪影误判为伪造，导致真实音频被错误拒绝。目前缺乏相关数据集支持系统研究。

2)  
- **核心方法**：本文构建了一个名为CodecDeepfakeDetection（CDD）的挑战性数据集，基于ASVspoof 5协议扩展，包含多种NAC和TTS系统生成的音频。通过系统实验，探究了在训练中将CoRS标注为“真实”或“伪造”对检测性能的影响。  
- **解决思路**：  
  - **数据集设计**：CDD包含真实音频、CoRS音频及CoSG伪造音频，覆盖了EnCodec、Mimi、DAC、XCodec2等多种NAC，以及Llasa、MARS5、CSM等TTS系统，确保了数据多样性和挑战性。  
  - **实验设置**：使用X-AASIST和LWBN作为检测器，在训练中分别将CoRS作为真实数据增强或伪造数据增强进行对比，评估在不同测试集（T-CoSG、T-CoRS、All）上的等错误率（EER）。  
  - **关键发现**：  
    - **NAC设计目标影响标注策略**：对于以压缩为目标的NAC（如DAC），将CoRS标注为伪造会导致检测器将真实音频判为伪造，性能下降；而将其标注为真实有助于学习编解码器不变特征，提升对CoSG的检测。  
    - **合成导向NAC的差异**：对于以生成为目标的NAC（如Mimi），将CoRS标注为伪造能更好地利用编解码器特定伪影，提升检测效果。  
    - **模型依赖性**：LWBN等单类学习模型对CoRS标注更敏感，标注策略不当会显著偏移真实类中心，降低性能。

3)  
- **任务与效果**：在CodecDeepfakeDetection数据集上评估音频深度伪造检测任务。  
  - **基线模型**：仅在CDD上训练（无CoRS增强）的模型在All测试集上EER约为20%，表明编解码器攻击具有挑战性。  
  - **标注策略优化**：  
    - 对压缩导向NAC，将CoRS标注为真实可使T-CoRS子集EER降低5-10%，提升对CoSG的检测。  
    - 对合成导向NAC，将CoRS标注为伪造能更好利用伪影，但需避免对真实音频的误判。  
  - **跨系统泛化**：训练中见过的NAC（如EnCodec、Mimi、DAC）在T-CoRS上EER较高，而未见的XCodec2性能较好，表明模型可能过拟合编解码器特定伪影。
</div>

</details>

---

## Spatial Audio Question Answering and Reasoning on Dynamic Source Movements
- **Authors**: Arvind Krishna Sridhar, Yinyi Guo, Erik Visser
- **Categories**: cs.SD, cs.AI
- **arXiv**: [https://arxiv.org/abs/2602.16334v1](https://arxiv.org/abs/2602.16334v1)
- **PDF**: [https://arxiv.org/pdf/2602.16334v1](https://arxiv.org/pdf/2602.16334v1)

空间音频理解旨在使机器能够解析复杂的听觉场景，尤其在声源随时间移动的情况下。本研究聚焦于动态推理的空间音频问答任务，要求模型直接从立体声音频中推断物体的运动轨迹、位置及方向变化。首先，我们提出一种以运动为核心的空间音频增强框架，能够从单声道孤立音频事件中合成多样化运动模式，实现可控且可扩展的训练数据生成。其次，我们设计了一种端到端多模态微调方法，引入“思考模式”使音频-语言模型在输出答案前生成显式的中间推理步骤。第三，我们探究了查询条件声源分离作为预处理阶段的影响，并比较了三种推理机制：无掩蔽、音频定位模型和真实掩蔽。实验结果表明，推理过程能增强声源分离的效果：当问题中仅涉及单个事件时，思考模式结合分离技术可使性能显著提升5.1%。这些发现揭示了运动建模、推理能力与分离质量之间的相互作用，为推进空间音频理解研究提供了新思路。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：空间音频问答旨在让机器理解包含移动声源的复杂听觉场景，是智能监控、机器人等领域的关键技术。  
- **既有方法问题**：现有方法（如BAT）主要处理静态声源，不支持开放式问答和动态运动推理；ELSA等模型缺乏细粒度时序推理能力；整体上，模型难以对声源运动进行显式、可解释的推理。

2)  
- **运动中心的数据增强**：从AudioSet中提取高质量单声道音频事件，通过预设轨迹（如接近、远离、横向移动）合成包含动态声源的立体声音频场景，并自动生成涵盖轨迹、径向变化、相对运动等7类问题的问答对，为训练提供可控且多样化的数据。  
- **端到端多模态微调与“思考模式”**：模型包含时序感知的空间音频编码器、Q-Former投影模块和大型语言模型。通过“思考模式”，模型在生成答案前先输出中间推理步骤，提升了可解释性和性能。训练采用两阶段策略：先冻结编码器学习音频-文本映射，再联合微调所有组件，并引入环境约束（如混响、事件重叠）以增强鲁棒性。  
- **查询条件源分离**：在推理时，利用音频接地模型根据问题中的关键词检测并掩码相关音频事件，仅保留与查询相关的音频部分。实验比较了无掩码、AGM掩码和真实掩码三种方式，发现源分离与“思考模式”协同作用，尤其当问题仅涉及单个事件时，性能提升显著（+5.1%）。

3)  
- **任务与效果**：在合成的空间音频QA数据集上评估，涵盖二值、多选和开放式问题。  
- **整体性能**：使用真实掩码和“思考模式”达到最高准确率56.1%，较基线BAT（14.7%）大幅提升。  
- **关键发现**：源分离质量与推理效果强相关，真实掩码下“思考模式”带来+2.0%增益；对于单事件问题，性能提升最显著（真实掩码+思考达68.7%准确率）。  
- **错误分析**：“思考模式”显著减少了方位、距离估计和答案-依据不匹配等错误类别。
</div>

</details>

---

## BAT: Better Audio Transformer Guided by Convex Gated Probing
- **Authors**: Houtan Ghaffari, Lukas Rauch, Christoph Scholz, Paul Devos
- **Categories**: cs.SD, cs.LG
- **arXiv**: [https://arxiv.org/abs/2602.16305v1](https://arxiv.org/abs/2602.16305v1)
- **PDF**: [https://arxiv.org/pdf/2602.16305v1](https://arxiv.org/pdf/2602.16305v1)

在计算机视觉领域，探针方法被广泛用于忠实评估自监督学习嵌入的质量，因为微调可能无法准确反映其内在特性。然而，音频自监督学习模型仍依赖微调，因为简单的探针方法无法充分释放其潜力，且在AudioSet等基准上竞争最优性能时会改变模型排名。因此，需要一种鲁棒且高效的探针机制来引导音频自监督学习向可靠、可复现的方向发展。本文提出凸门控探针方法，这是一种基于原型的方法，显著缩小了音频领域中微调与探针之间的性能差距。该方法通过门控机制高效利用所有冻结层，并揭示潜在任务相关信息的分布位置。在此方法指导下，我们重构了当前最优音频模型的自监督学习流程，改进了其沿用的传统实现方案。通过优化数据预处理、模型架构和预训练策略，我们提出了更优音频Transformer模型，并在音频基准测试中取得了新的最优性能。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：音频自监督学习（SSL）模型在AudioSet等基准上的评估严重依赖微调，而非像计算机视觉领域那样使用冻结特征的探测方法。  
- **既有问题**：  
  - 微调引入超参数敏感性等混杂变量，可能掩盖SSL表示的真实质量，导致结果不可靠且难以复现。  
  - 简单的线性探测无法充分释放音频嵌入的潜力，造成性能差距，从而错误地依赖微调来竞争SOTA。  
  - 当前SOTA模型（如EAT、SSLAM）基于遗留代码实现，存在未记录的架构细节和优化实践，损害了可复现性。

2)  
论文通过引入**凸门控探测（CGP）** 并基于其指导构建**更好的音频Transformer（BAT）** 来解决上述问题：  
- **CGP方法**：  
  - 采用基于原型的探测机制，通过可学习的软门控向量对冻结主干的所有层嵌入进行加权聚合，生成单一表示。  
  - 将聚合后的表示与K个原型计算余弦相似度，并对相似度进行最小-最大池化，再与[CLS]标记的相似度拼接，最终输入线性分类器。  
  - 该方法高效利用全部层，显著缩小了冻结探测与微调之间的性能差距，并能定位任务相关的潜在信息。  
- **BAT的改进**：  
  - **数据预处理**：使用现代Mel频谱图提取（支持分贝尺度压缩和局部归一化），替代依赖全局统计量的传统流程，提升鲁棒性和部署便利性。  
  - **目标生成**：在注意力机制中引入门控（基于Sigmoid的输入相关稀疏化），改善多头自注意力的输出质量，并使用编码器块的整体输出（而非仅MLP输出）作为SSL目标，提升语义质量。  
  - **模型架构**：将轻量级CNN解码器替换为更强大的ViT解码器，减轻编码器深层对低级重建任务的负担，使其更专注于学习高层语义，从而提升冻结嵌入的质量。  
- **整体贡献**：CGP提供了可靠且高效的评估协议；BAT则通过系统化的流程改进，实现了更优且可复现的音频SSL模型。

3)  
在多个音频基准任务上，BAT均取得了SOTA或具有竞争力的效果：  
- **AudioSet**：在AS-20k和AS-2M上，BAT的微调性能（mAP分别为41.32和48.55）优于复现的基线模型（EAT、SSLAM）；其冻结探测性能（CGP）显著超过基线，例如在AS-20k上CGP达到37.52 mAP，较基线提升约2-3个百分点。  
- **ESC-50**：BAT的CGP性能（95.80%）甚至超过了其微调结果（95.52%），展示了冻结嵌入的高质量。  
- **Speech Commands V2**：BAT在微调和CGP评估下均达到最佳性能（如CGP为97.13%）。  
- **关键结论**：BAT的改进使其编码器产生了更线性可分的嵌入，CGP有效缩小了冻结评估与微调之间的差距，为音频SSL提供了更可靠、可复现的评估框架。
</div>

</details>

---

## Color-based Emotion Representation for Speech Emotion Recognition
- **Authors**: Ryotaro Nagase, Ryoichi Takashima, Yoichi Yamashita
- **Categories**: eess.AS, cs.AI, cs.SD
- **arXiv**: [https://arxiv.org/abs/2602.16256v1](https://arxiv.org/abs/2602.16256v1)
- **PDF**: [https://arxiv.org/pdf/2602.16256v1](https://arxiv.org/pdf/2602.16256v1)

传统语音情感识别通常依赖分类或维度标签，但这类方法在情感多样性与可解释性表征方面存在局限。为突破此限制，本研究聚焦色相、饱和度与明度等颜色属性，将情感表征为连续且可解释的数值。通过众包方式对情感语音语料库进行颜色属性标注并开展分析。在此基础上，采用机器学习与深度学习技术构建了面向语音情感识别的颜色属性回归模型，并探索了颜色属性回归与情感分类的多任务学习方法。实验结果表明：颜色属性与语音情感存在显著关联，所构建的回归模型能有效实现语音情感的颜色属性预测，且多任务学习策略可同步提升两项任务的性能表现。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：语音情感识别（SER）传统上依赖分类（如快乐、愤怒）或维度（如效价、唤醒度）标签。  
- **既有问题**：  
  - 分类方法无法描述混合或模糊情感，受限于预定义类别。  
  - 维度方法虽能捕捉细微差异，但解释性差，常需专业知识。  
  - 两者均难以同时兼顾情感多样性与直观可解释性。

2)  
- **核心方法**：提出基于颜色属性（色调、饱和度、明度）的SER框架，将情感表示为连续且可解释的数值。  
- **解决步骤**：  
  - **数据标注**：通过众包为日语情感语音数据集（JVNV）添加颜色属性标签，分析其与分类情感的关联（如快乐对应黄色调，愤怒对应红色调）。  
  - **回归模型**：使用支持向量回归（SVR）和深度神经网络（DNN）从语音中直接预测颜色属性。DNN采用HuBERT预训练模型，损失函数为一致性相关系数（CCC）损失。  
  - **多任务学习**：联合训练颜色属性回归与六分类情感分类任务，通过加权损失（交叉熵与CCC损失结合）使两者相互促进。  
- **优势**：  
  - 颜色属性提供连续、直观的情感表示，弥补了分类与维度方法的不足。  
  - 多任务学习利用颜色与分类标签的互补性，提升模型性能。

3)  
- **任务与效果**：  
  - **颜色属性回归**：在JVNV数据集上，DNN模型取得最佳结果（色调角误差最低31.3°，饱和度CCC最高0.533，明度CCC最高0.794），证明可从语音有效预测颜色属性。  
  - **多任务学习**：当回归与分类任务权重平衡时（α=0.9），分类准确率达90.8%，较单任务分类（88.3%）提升2.5个百分点；同时回归性能也优于单任务模型。  
  - **模型泛化**：基于自监督学习（HuBERT）的特征显著优于传统声学特征，验证了颜色表示在新框架下的可行性。
</div>

</details>

---

## How Much Does Machine Identity Matter in Anomalous Sound Detection at Test Time?
- **Authors**: Kevin Wilkinghoff, Keisuke Imoto, Zheng-Hua Tan
- **Categories**: eess.AS, cs.SD
- **arXiv**: [https://arxiv.org/abs/2602.16253v1](https://arxiv.org/abs/2602.16253v1)
- **PDF**: [https://arxiv.org/pdf/2602.16253v1](https://arxiv.org/pdf/2602.16253v1)

异常声音检测（ASD）基准测试通常假设测试时被监测机器的身份已知，且录音按机器分别评估。然而，在实际监测场景中，多台已知机器同时运行，测试录音可能无法可靠归属到特定机器，而要求机器身份会带来部署限制，例如每台机器需配备专用传感器。为揭示在标准按机器评估下隐藏的性能下降及方法间鲁棒性差异，我们提出对ASD评估协议进行最小修改：将多台机器的测试录音合并，在推理时不依赖机器身份进行联合评估。训练数据和评估指标保持不变，机器身份标签仅用于事后评估。对代表性ASD方法的实验表明，放宽这一假设会暴露出在标准按机器评估下隐藏的性能下降及方法间鲁棒性差异，且这些性能下降与隐式机器识别准确率密切相关。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：异常声音检测（ASD）在机器状态监测中广泛应用，但现有基准（如DCASE挑战赛）默认测试时已知机器身份，并按机器分别评估。  
- **既有问题**：实际监控场景中，多台已知机器可能同时运行，测试录音无法可靠归属到特定机器。现有方法依赖机器特定模型、统计信息或延迟聚合，假设不成立时，其鲁棒性差异被标准评估掩盖，限制了系统在真实部署中的可扩展性和灵活性。

2)  
- **核心方法**：论文提出一个最小的评估协议修改，仅移除测试时的机器身份信息，其他所有设置（训练数据、评估指标）保持不变。  
- **具体实施**：
  - **测试集构建**：将来自多台已知机器的所有测试录音合并为一个混合测试集，机器身份标签仅在事后评估时使用。
  - **任务定义**：主要任务仍是异常检测，系统需为每个录音生成异常分数；附加任务是通过分数聚合隐式预测机器身份，作为诊断工具。
  - **理论关联**：当机器身份未知时，异常检测性能取决于隐式机器识别的准确性。若系统无法正确选择对应的机器特定正态模型，检测性能就会下降。
- **解决思路**：通过该协议，可以隔离并量化“机器身份已知”这一假设对ASD性能的影响，揭示不同方法在身份未知时的鲁棒性差异，并将其与隐式机器识别精度直接关联。

3)  
- **评估任务**：在DCASE2020至2025的多个公开数据集上，评估了判别式模型、基于预训练嵌入的无训练方法、机器特定模型等代表性ASD方法。  
- **取得效果**：
  - 判别式模型在机器身份未知时性能下降最小（归一化降解约2-3%），表现出最强鲁棒性。
  - 无训练嵌入方法和机器特定模型性能下降显著（降解可达约12-20%），对隐式机器识别错误更敏感。
  - 实验证实了异常检测性能降解与隐式机器识别精度之间的强负相关关系，为未来ASD基准测试引入该评估维度提供了依据。
</div>

</details>

---

## Real time fault detection in 3D printers using Convolutional Neural Networks and acoustic signals
- **Authors**: Muhammad Fasih Waheed, Shonda Bernadin
- **Categories**: eess.SP, cs.SD, eess.AS
- **arXiv**: [https://arxiv.org/abs/2602.16118v1](https://arxiv.org/abs/2602.16118v1)
- **PDF**: [https://arxiv.org/pdf/2602.16118v1](https://arxiv.org/pdf/2602.16118v1)

三维打印过程的可靠性与质量，关键在于能否及时检测出机械故障。传统监测方法多依赖视觉检查与硬件传感器，不仅成本较高且监测范围有限。本文研究了一种可扩展的非接触式方法，通过实时音频信号分析来检测三维打印机中的机械故障。通过采集并分类打印过程中的声发射信号，我们旨在识别喷嘴堵塞、线材断裂、皮带打滑及其他常见机械故障。利用卷积神经网络，我们实现了能够实时进行音频分类以快速检测这些故障的算法。研究方法包括开展一系列受控实验以收集音频数据，随后应用先进的机器学习模型进行故障检测。此外，我们回顾了制造业与三维打印领域中基于音频的故障检测相关文献，从而将本研究置于更广泛的学术背景中。初步结果表明，结合机器学习技术分析音频信号，能够为增强实时故障检测提供可靠且经济高效的解决方案。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：3D打印的可靠性与质量高度依赖对机械故障的及时检测。  
- **既有方法问题**：  
  - **传统方法**（如人工视觉检查、硬件接触式传感器）成本高、监测范围有限、无法实时连续监控，且易受主观因素和环境干扰。  
  - **摄像头方案**存在视野局限或多系统成本高、实施复杂、对光照敏感等问题。  

2)  
- **核心方法**：提出一种基于**声学信号**与**卷积神经网络（CNN）** 的非接触式实时故障检测方法。  
- **关键步骤**：  
  - **数据采集与预处理**：使用麦克风采集3D打印机挤出机在正常与故障状态下的声音，并通过**带通滤波（100–1200 Hz）** 和**减法降噪**技术滤除环境噪声。  
  - **特征提取**：将音频信号转换为**声谱图**（时频表示），作为CNN的输入图像。  
  - **模型构建与训练**：采用**CNN模型**（结合迁移学习）对声谱图进行分类，以识别喷嘴堵塞、线材断裂、皮带打滑等故障的独特声学特征。  
  - **实时监测**：系统持续分析打印过程中的声学信号，实现故障的即时检测与预警。  
- **方法优势**：  
  - **非侵入且成本低**：仅需廉价麦克风，无需改造打印机硬件。  
  - **高精度与可扩展性**：CNN能有效提取声谱图中的复杂模式，提升检测准确性；方法易于适配不同故障类型与打印机型号。  

3)  
- **任务与效果**：  
  - **故障检测任务**：针对喷嘴堵塞、线材断裂、皮带打滑等常见机械故障进行实时分类。  
  - **性能指标**：在256个音频样本的数据集上，模型达到约**91%准确率、88%精确率、85%召回率**，综合F1分数为86.5%。  
  - **对比优势**：优于传统振动传感器方法（准确率75–85%），实现了**高精度、低成本、非接触式**的实时监测，为3D打印质量控制和预测性维护提供了有效解决方案。
</div>

</details>

---
