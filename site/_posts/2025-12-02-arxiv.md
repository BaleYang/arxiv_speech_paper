---
layout: post
title: "arXiv Daily – 2025-12-02"
tags: [arxiv, cs.SD, eess.AS]
---

以下为 2025-12-02（CST，北京时间）窗口内更新的论文中文译文：
- 时间窗口（锚点 08:50 CST）：2025-12-01 08:50 — 2025-12-02 08:50
- 抓取总数：7 篇 | 本页显示：7 篇（去重/过滤后）

## Parallel Delayed Memory Units for Enhanced Temporal Modeling in Biomedical and Bioacoustic Signal Analysis
- **Authors**: Pengfei Sun, Wenyu Jiang, Paul Devos, Dick Botteldooren
- **Categories**: cs.SD, cs.NE
- **arXiv**: [https://arxiv.org/abs/2512.01626v1](https://arxiv.org/abs/2512.01626v1)
- **PDF**: [https://arxiv.org/pdf/2512.01626v1](https://arxiv.org/pdf/2512.01626v1)

在音频、生物声学和生物医学信号分析领域，尤其是在数据稀缺的环境中，先进的深度学习架构（特别是循环神经网络）已得到广泛应用。门控循环神经网络虽仍具效力，但在某些场景下可能存在参数过多、训练效率不足的问题，而线性循环神经网络往往难以充分捕捉生物信号中固有的复杂性。为应对这些挑战，本文提出并行延迟记忆单元——一种面向音频与生物声学信号的延迟门控状态空间模块，旨在优化短期时序信用分配。该单元通过门控延迟线机制，增强了短期时序状态交互与记忆效率。与以往将时序动态嵌入延迟线架构的延迟记忆单元不同，并行延迟记忆单元进一步利用勒让德记忆单元将时序信息压缩为向量表示。该设计可视为一种因果注意力机制，使模型能够动态调整对历史状态的依赖，提升实时学习性能。值得注意的是，在低信息量场景中，其门控机制类似于跳跃连接，能够绕过状态衰减并保留早期表征，从而促进长期记忆保持。并行延迟记忆单元采用模块化设计，支持并行训练与序列推断，并可便捷地集成至现有线性循环神经网络框架中。此外，我们还提出了该架构的双向、高效及脉冲变体，各自在性能或能效方面带来额外提升。在多种音频与生物医学基准测试上的实验结果表明，并行延迟记忆单元显著提升了记忆容量与整体模型性能。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：音频、生物声学和生物医学信号分析常依赖循环神经网络（RNN）和Transformer。  
- **既有方法问题**：  
  - 门控RNN存在梯度消失、训练时间长且难以并行化。  
  - Transformer需完整序列，计算和内存开销随序列长度呈二次增长，不适合实时或资源受限场景。  
  - 线性RNN（如LMU）虽能捕获长期依赖，但未能充分利用信号中动态的短期交互。

2)  
- **核心方法**：提出并行延迟记忆单元（PDMU），作为延迟门控的状态空间模块，基于LMU框架构建。  
- **关键设计**：  
  - **延迟门控机制**：通过门控延迟线将当前记忆信息动态分配到未来时间点，增强短期时间状态交互。  
  - **并行训练与顺序推理**：利用线性时不变系统特性，支持并行训练，同时保持因果、实时推理能力。  
  - **变体扩展**：  
    - 双向PDMU（Bi-PDMU）捕获过去与未来时间关系。  
    - 高效PDMU（EPDMU）每次仅激活一个延迟门以降低计算开销。  
    - 脉冲DMU结合脉冲神经元，提升能效。  
- **解决方式**：  
  - 通过延迟门控实现短期时间信用分配，弥补LMU在短期交互上的不足。  
  - 模块化设计可轻松集成到现有线性RNN框架，在数据稀缺和边缘计算场景中优化性能与能效。

3)  
- **任务与效果**：  
  - **咳嗽音频分类**（COUGHVID）：PDMU准确率达82.45%，结合CNN时提升至85.48%，优于LSTM（76.41%）。  
  - **EEG注意力检测**（WithMe）：PDMU在内部受试者准确率达84.17%，双向变体在未见受试者上达77.13%，超越EEGNet和LSTM。  
  - **脉冲语音识别**（SHD）：脉冲DMU准确率90.98%，非脉冲PDMU达84.57%，均优于基线RNN。  
  - **语音命令识别**（GSC）：PDMU准确率96.93%，脉冲DMU达96.39%，在参数较少下保持竞争力。  
  - **置换序列MNIST**：PDMU准确率98.22%，优于多数RNN变体，脉冲DMU达96.07%。
</div>

</details>

---

## LLM2Fx-Tools: Tool Calling For Music Post-Production
- **Authors**: Seungheon Doh, Junghyun Koo, Marco A. Martínez-Ramírez, Woosung Choi, Wei-Hsiang Liao, Qiyu Wu, Juhan Nam, Yuki Mitsufuji
- **Categories**: cs.SD
- **arXiv**: [https://arxiv.org/abs/2512.01559v1](https://arxiv.org/abs/2512.01559v1)
- **PDF**: [https://arxiv.org/pdf/2512.01559v1](https://arxiv.org/pdf/2512.01559v1)

本文介绍了LLM2Fx-Tools，一个多模态工具调用框架，用于为音乐后期制作生成可执行的音频效果序列（效果链）。该框架利用大语言模型（LLM）理解音频输入，在思维链（CoT）规划的引导下选择音频效果类型、确定其顺序并估算参数。我们还提出了LP-Fx，这是一个新的指令跟随数据集，包含针对音频效果模块的结构化CoT标注和工具调用信息。实验表明，通过自回归序列建模、工具调用和CoT推理，LLM2Fx-Tools能够从未处理与已处理的音频对中推断出效果链及其参数。我们进一步在风格迁移场景中验证了该系统，其中音频效果信息从参考源迁移并应用于新内容。最后，基于LLM的自动评估表明，我们的方法能够为音乐制作相关查询生成恰当的CoT推理与响应。据我们所知，这是首个将基于LLM的工具调用应用于音频效果模块的研究，实现了可解释且可控的音乐制作流程。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：音乐后期制作中，音频效果链（Fx-chain）的估计依赖专家经验，过程繁琐。现有自动方法存在局限：
  - 基于梯度的方法需要可微的音频效果模块，适用性受限。
  - 基于回归或信号处理的方法配置固定，无法动态选择效果类型及确定顺序。
  - 缺乏可解释性，仅输出效果链而无人类可读的推理过程。

2)  
**核心方法**：LLM2Fx-Tools 是一个多模态工具调用框架，通过结合思维链（CoT）规划和工具调用，解决上述问题。具体包括：
- **工具调用架构**：
  - 使用大型语言模型（LLM）作为核心，通过音频编码器和适配器将音频输入映射到文本嵌入空间，实现多模态理解。
  - 将音频效果模块视为外部可执行工具，LLM 生成结构化的工具调用序列（含效果类型、顺序及参数）。
- **思维链规划**：
  - CoT 将复杂任务分解为可解释的子步骤：用户输入分析、效果模块选择、处理顺序确定、参数规划。
  - 作为自回归生成中的上下文条件，桥接用户查询与动作计划，提升准确性和可解释性。
- **训练与优化**：
  - 采用多阶段训练：先进行模态对齐预训练（学习音频与效果链的映射），再通过 LoRA 微调 LLM，融入完整对话数据（指令、CoT、响应、工具调用）。
  - 引入数字令牌损失（NTL），优化参数估计的数值准确性。
- **鲁棒性处理**：
  - 使用 Fx-Removal 和 Fx-Normalization 预处理音频，对齐环境分布，生成伪干声音频。
  - 训练中随机掩码干声音频，使模型适应盲估计场景（仅参考音频可用）。

3)  
- **反向工程任务**：在 LP-Fx 数据集上评估，LLM2Fx-Tools 在效果链规划中达到 80% 的效果分类准确率和 0.56 的排序相关系数，优于回归和多任务基线。在感知距离和嵌入相似性指标上表现最佳，人类听力测试（MUSHRA）中显著优于其他方法。
- **音频效果风格迁移任务**：在跨数据集（MoisesDB 到 MedleyDB）的盲估计设置下，LLM2Fx-Tools 在 DSP 特征距离和嵌入相似性上均取得最优结果，展示了良好的泛化能力。
- **自然语言生成任务**：通过 LLM-as-a-judge 评估，在工具调用成功率（99.8%）、指令跟随质量和思维链质量上均接近或超过先进闭源模型（如 Gemini 2.5 Flash）。
</div>

</details>

---

## Q2D2: A Geometry-Aware Audio Codec Leveraging Two-Dimensional Quantization
- **Authors**: Tal Shuster, Eliya Nachmani
- **Categories**: cs.SD, cs.AI, cs.IT, cs.LG, eess.SP
- **arXiv**: [https://arxiv.org/abs/2512.01537v1](https://arxiv.org/abs/2512.01537v1)
- **PDF**: [https://arxiv.org/pdf/2512.01537v1](https://arxiv.org/pdf/2512.01537v1)

近年来，神经音频编解码器在重建质量方面取得了显著进展，通常依赖于残差向量量化（RVQ）、向量量化（VQ）和有限标量量化（FSQ）等量化方法。然而，这些量化技术限制了潜在空间的几何结构，使得特征间相关性难以捕捉，导致表示学习、码本利用率和码率效率低下。本文提出二维量化（Q2D2），该量化方案将特征对投影到结构化二维网格（如六边形、菱形或矩形平铺）上，并量化至最近的网格值，从而生成由网格层级乘积定义的隐式码本，其码本规模与传统方法相当。尽管其几何形式简洁，Q2D2 仍提升了音频压缩效率，在保持先进重建质量的同时实现了低码率和高码本利用率。具体而言，在语音领域的广泛实验中，与前沿模型相比，Q2D2 在多项客观和主观重建指标上均达到竞争性乃至更优的性能。系统的消融实验进一步验证了所提设计方案的有效性。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：神经音频编解码器（如RVQ、VQ、FSQ）在音频重建质量上取得进展，但现有量化方法存在局限。
- **既有问题**：
  - **潜在空间几何结构受限**：传统量化（如VQ、RVQ）导致潜在空间结构复杂，难以捕捉特征间相关性。
  - **码本利用不足**：随着码本增大，许多码字未被使用，需依赖重新初始化等技巧稳定训练。
  - **特征关联性弱**：FSQ虽简单高效，但独立量化各通道，忽略通道间相关性，表示能力受限。

2)  
论文提出**Q2D2**（二维量化）方法，核心是通过结构化二维网格量化特征对，以解决传统方法的几何限制与效率问题。具体方案如下：

- **特征对分组与二维投影**：
  - 将编码器输出的特征通道两两配对，映射到二维空间。
  - 使用预定义的结构化网格（如菱形、六边形、矩形）作为量化基础，网格点由每对特征的量化级数定义。

- **几何感知量化**：
  - 每个特征对通过最近邻搜索量化到网格中最接近的点。
  - 网格类型（如菱形）提供更高的空间填充效率，能更均匀地覆盖潜在空间，降低量化误差。
  - 整体码本由所有配对网格的笛卡尔积隐式定义，无需学习显式码本嵌入。

- **训练与优化**：
  - 采用轻量级线性投影层将特征映射到量化空间，并使用直通估计器（STE）保持梯度可微。
  - 无需依赖辅助损失（如承诺损失）或码本重置技巧，即实现高码本利用率与训练稳定性。

- **优势体现**：
  - **保留FSQ的简洁性**：避免复杂码本学习，参数少且易于训练。
  - **增强特征相关性建模**：通过二维联合量化，自然捕捉通道间关联，提升表示能力。
  - **高压缩效率**：在低码率（如1-6.9 kbps）下实现高质量重建，且码本利用率接近100%。

3)  
- **任务与数据集**：在语音重建任务上进行了广泛评估，包括LibriTTS（干净/噪声环境）、LJSpeech（域外数据）和LibriSpeech。
- **效果**：
  - **客观指标**：在1 kbps（75 token/s）、3.3 kbps（166 token/s）和6.9 kbps（333 token/s）设置下，Q2D2在UTMOS、PESQ、STOI等指标上均优于或媲美SOTA模型（如DAC、Encodec、WavTokenizer）。
  - **主观评估**：MUSHRA和CMOS测试显示，Q2D2在低码率下重建质量接近原始音频，优于同类单量化器基线。
  - **语义表示**：在ARCH基准的语音分类任务中，Q2D2仅用53 token/s即超越多量化器模型，表明其能保留丰富的语义信息。
  - **消融验证**：菱形网格、适中维度（如6维）和平衡量化级数能最优权衡码率、利用率和重建质量。
</div>

</details>

---

## Identifiability Conditions for Acoustic Feedback Cancellation with the Two-Channel Adaptive Feedback Canceller Algorithm
- **Authors**: Arnout Roebben, Toon van Waterschoot, Jan Wouters, Marc Moonen
- **Categories**: eess.AS
- **arXiv**: [https://arxiv.org/abs/2512.01466v1](https://arxiv.org/abs/2512.01466v1)
- **PDF**: [https://arxiv.org/pdf/2512.01466v1](https://arxiv.org/pdf/2512.01466v1)

在包含麦克风与扬声器且处于同一声学环境的音频信号处理应用中，扬声器信号可能反馈至麦克风，从而形成闭环系统并可能引发系统失稳。为消除这种声学耦合，基于预测误差方法（PEM）的反馈消除算法旨在通过假设输入信号可用自回归（AR）模型建模来识别扬声器至麦克风间的反馈路径。已有研究表明，当麦克风至扬声器的前向路径具有充分时变性或非线性，或前向路径延迟等于或超过AR模型阶数时，该PEM框架及其衍生算法能准确识别反馈路径。本文证明，对于一种特定的基于PEM的算法——双通道自适应反馈消除器（2ch-AFC），上述基于延迟的条件可推广为基于可逆性的条件：当前向路径前馈滤波器的阶数超过AR模型阶数时，即可实现参数可辨识性。此外，2ch-AFC算法中相关矩阵求逆的条件数可作为监测可辨识性程度的指标。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：在助听器、扩音系统等包含麦克风和扬声器的音频应用中，声学反馈会导致闭环系统不稳定，产生啸叫。  
- **既有方法问题**：基于预测误差方法（PEM）的反馈消除算法需满足可辨识性条件才能无偏估计反馈路径。现有条件要求前向路径时变/非线性，或前向路径延迟≥自回归（AR）模型阶数，限制了前向路径设计的灵活性。

2)  
- **核心方法**：本文聚焦于双通道自适应反馈消除器（2ch-AFC）算法，提出了一种基于可逆性的广义可辨识性条件。  
- **具体解决方式**：  
  - **理论推导**：通过分析2ch-AFC算法中相关矩阵的秩，证明当**前向路径前馈滤波器的阶数（LGN）超过AR模型阶数（LA）时，即可实现反馈路径的无偏辨识**，即 LGN > LA。  
  - **条件推广**：该条件将原有的延迟条件（要求前LA个前馈系数为零）推广为更一般的形式，允许这些系数非零，从而为前向路径的信号处理设计提供了更大灵活性。原有的延迟条件成为该条件的一个特例。  
  - **实用性增强**：该条件表明，使用平稳（非时变）的全通滤波器也能实现可辨识性，无需依赖时变处理。  
  - **监测指标**：提出使用算法中相关矩阵逆的条件数作为可辨识性的监测度量，条件数越大表示辨识问题越病态。

3)  
- **验证任务**：在模拟的声学反馈场景中，使用不同前向路径滤波器（FIR、IIR全通、纯延迟）和输入信号（语音成形噪声、真实语音）进行系统辨识。  
- **取得效果**：  
  - 实验证实，当满足 LGN > LA 时，系统能够成功辨识反馈路径，表现为**正的附加稳定增益（ASG）**，提升了系统稳定性。  
  - 相关矩阵的条件数变化与ASG性能相符，验证了其作为可辨识性度量指标的有效性。  
  - 即使在输入信噪比较低（-5 dB）的情况下，算法仍能保持鲁棒性，获得正的ASG。
</div>

</details>

---

## MEGConformer: Conformer-Based MEG Decoder for Robust Speech and Phoneme Classification
- **Authors**: Xabier de Zuazo, Ibon Saratxaga, Eva Navas
- **Categories**: cs.CL, cs.LG, cs.NE, cs.SD
- **arXiv**: [https://arxiv.org/abs/2512.01443v1](https://arxiv.org/abs/2512.01443v1)
- **PDF**: [https://arxiv.org/pdf/2512.01443v1](https://arxiv.org/pdf/2512.01443v1)

本文提出基于Conformer架构的解码器，用于LibriBrain 2025 PNPL竞赛中的两项基础MEG任务：语音检测与音素分类。该方法将轻量化Conformer模型适配于原始306通道MEG信号，通过轻量卷积投影层与任务专用头部实现处理。针对语音检测任务，我们设计了面向MEG的SpecAugment数据增强策略，首次探索了MEG专用增强方法。在音素分类任务中，采用逆平方根类别加权与动态分组加载器处理100样本平均示例，并通过简单的实例级归一化有效缓解了保留数据集上的分布偏移问题。基于官方标准赛道划分方案并采用宏观F1分数进行模型选择，我们的最佳系统在排行榜上分别取得88.9%（语音检测）与65.8%（音素分类）的评分，超越竞赛基线并在两项任务中均位列前十。完整技术文档、源代码与模型检查点已公开于https://github.com/neural2speech/libribrain-experiments。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
研究背景聚焦于利用非侵入性脑信号（如脑磁图MEG）解码语音，这是神经信号处理和脑机接口的核心挑战。既有方法通常使用线性基线或卷积/Transformer架构，但面临以下问题：
- 现有模型在处理MEG信号的时空模式时，可能未能充分结合局部与全局依赖关系。
- 数据分布偏移（如训练集与保留集之间的统计差异）影响模型泛化能力。
- 任务特定挑战，如语音检测需增强数据鲁棒性，音素分类需处理类别不平衡和信号平均问题。

2)  
论文核心方法MEGConformer基于Conformer架构（结合自注意力与卷积），通过以下设计解决上述问题：
- **统一架构适配**：采用轻量级1D卷积层将原始306通道MEG信号投影至Conformer输入，共享主干网络，针对语音检测和音素分类任务分别定制头部和超参数（如层数、注意力头数）。
- **鲁棒输入处理**：
  - 语音检测任务引入MEGAugment（基于SpecAugment的MEG特定数据增强），包括时间掩码和频带阻隔掩码，以提升模型鲁棒性。
  - 音素分类任务采用实例级归一化，逐样本逐通道跨时间归一化，有效缓解训练集与保留集之间的分布偏移。
- **任务优化策略**：
  - 语音检测使用2.5秒窗口和滑动步长，增加训练多样性。
  - 音素分类使用逆平方根类别加权处理不平衡，并设计动态分组加载器，对100样本平均信号进行重组以增强训练样本独立性。
  - 通过集成多个模型种子（多数投票）进一步提升音素分类稳定性。

3)  
在LibriBrain 2025 PNPL竞赛的标准赛道中，MEGConformer在两个任务上取得显著效果：
- **语音检测**：F1-macro达到88.9%，超越官方基线（68.0%），进入排行榜前十。
- **音素分类**：F1-macro达到65.8%，同样超越基线（60.4%），位列前十。
关键改进包括：延长输入窗口、定制Conformer结构、动态分组和实例归一化，这些设计显著提升了模型在保留集上的泛化性能。
</div>

</details>

---

## Masked Symbol Modeling for Demodulation of Oversampled Baseband Communication Signals in Impulsive Noise-Dominated Channels
- **Authors**: Oguz Bedir, Nurullah Sevim, Mostafa Ibrahim, Sabit Ekin
- **Categories**: eess.SP, cs.LG, cs.SD
- **arXiv**: [https://arxiv.org/abs/2512.01428v1](https://arxiv.org/abs/2512.01428v1)
- **PDF**: [https://arxiv.org/pdf/2512.01428v1](https://arxiv.org/pdf/2512.01428v1)

自然语言处理领域的最新突破表明，通过掩码标记预测训练的Transformer网络中的注意力机制，能够使模型捕捉标记的语义上下文并内化语言语法。尽管Transformer在通信系统中的应用是一个新兴领域，但物理波形中的上下文概念仍未得到充分探索。本文通过重新审视由脉冲成形重叠引起的符号间贡献（ISC）来填补这一空白。我们不再将ISC视为干扰，而是将其视为嵌入过采样复基带信号中的确定性上下文信息源。受Transformer双向编码器表示方法的启发，我们提出了面向物理（PHY）层的掩码符号建模框架。在该框架中，随机掩码一部分符号对齐的样本，Transformer利用周围的“中间”样本预测缺失的符号标识符。通过这一目标，模型学习复基带波形的潜在语法。我们通过将该框架应用于受脉冲噪声干扰信号的解调任务来展示其潜力——模型能够利用学习到的上下文推断受损片段。研究结果表明，接收机有望实现从“单纯检测”到“理解”通信信号的转变，这为上下文感知的物理层设计开辟了新途径。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
**研究背景与既有方法的问题**
- **背景**：脉冲整形（如升余弦滤波器）在过采样基带信号中引入了符号间贡献（ISC），即每个样本包含相邻符号的信息。传统上，这被视为需要均衡处理的干扰。
- **问题**：现有方法主要将ISC视为“干扰”，通过均衡等技术被动处理，未能充分利用其作为确定性上下文信息的潜力。同时，在冲激噪声主导的信道中，传统检测方法性能受限，缺乏对信号“语境”的理解和利用。

2)  
**论文核心方法如何解决上述问题**
本文提出**掩码符号建模（MSM）**，一个受BERT启发的自监督框架，旨在从物理层波形中学习上下文表示。其核心是通过掩码预测任务，让模型内化脉冲整形信号的结构。

- **方法框架**：
  - **输入与掩码**：模型输入为过采样（8 SPS）的复基带信号（分离为I/Q两路实数序列）。在训练时，随机掩码15%符号对应的样本段（置零）。
  - **模型架构**：使用基于Transformer的编码器（具体为Reformer块，采用LSH注意力以提高效率）。掩码后的信号经可学习的1D投影层映射为512维嵌入，并加入正弦位置编码。
  - **预测任务**：模型仅利用周围未掩码的样本，预测每个被掩码符号的标识符（ID）。符号ID是一个涵盖所有调制星座点的离散词汇表。
  - **训练目标**：通过交叉熵损失（仅针对掩码位置）进行训练，使模型学会从“中间”样本推断缺失符号，从而掌握由ISC形成的信号“语法”。

- **如何解决问题**：
  - **利用而非消除ISC**：MSM主动将ISC重新定义为可学习的上下文信息源，通过掩码预测迫使模型理解符号间的依赖关系。
  - **实现信号“解读”**：模型不仅检测符号，还学习波形的潜在结构，能够像理解语言一样理解物理波形。
  - **应用于冲激噪声**：在推理阶段，可将受冲激噪声污染的符号段主动掩码，然后利用模型学到的上下文信息进行恢复，从而提升在恶劣信道下的 demodulation 鲁棒性。

3)  
**在哪些任务上取得了怎样的效果**
- **任务**：在**冲激噪声（米德尔顿A类）主导的信道中进行符号解调**。具体评估模型在符号被噪声污染后，通过掩码并利用上下文进行恢复的能力。
- **效果**：
  - 在无噪声条件下，模型对不同调制格式（BPSK、QPSK、QAM等）的掩码符号预测准确率很高（SER很低），证明了其学习上下文的能力。
  - 在强冲激噪声（Γ=10⁻⁶）下，由于高斯噪声分量可忽略，模型性能在很宽的SNR范围内保持稳定。
  - 在中等冲激噪声（Γ=10⁻³）下，低SNR时高斯噪声会降低性能，但随着SNR提升，性能趋于稳定，接近强冲激噪声下的水平。
- **结论**：结果表明，MSM能够利用学到的信号上下文有效恢复被冲激噪声破坏的符号，为实现“解读”而不仅仅是“检测”信号的接收机提供了新途径。
</div>

</details>

---

## ZO-ASR: Zeroth-Order Fine-Tuning of Speech Foundation Models without Back-Propagation
- **Authors**: Yuezhang Peng, Yuxin Liu, Yao Li, Sheng Wang, Fei Wen, Xie Chen
- **Categories**: cs.MM, cs.SD
- **arXiv**: [https://arxiv.org/abs/2512.01267v1](https://arxiv.org/abs/2512.01267v1)
- **PDF**: [https://arxiv.org/pdf/2512.01267v1](https://arxiv.org/pdf/2512.01267v1)

针对自动语音识别任务微调预训练语音基础模型已成为主流方法，但其通常受限于高昂的GPU显存需求。本文提出ZO-ASR，一种基于零阶优化的高效显存微调方法，该方法通过前向传播估计梯度，避免了反向传播与激活值显存占用。结合SGD优化器后，ZO-ASR-SGD仅需推理级显存即可完成ASR模型微调。我们在监督与非监督任务上进行了全面评估：在Whisper-Large-V3的监督域适应任务中，ZO-ASR的多查询机制提升了鲁棒性，相比零样本基线实现了最高18.9%的词错误率相对降低，且优于现有零阶优化方法；在Wav2Vec2-Base的非监督测试时适应任务中，ZO-ASR性能略低于一阶优化器Adam。这种无需反向传播的方法为计算资源受限或梯度不可访问场景下的ASR模型微调提供了可行的解决方案。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：自动语音识别（ASR）基础模型（如Whisper-Large-V3）参数量巨大（超过15亿），其微调需要大量GPU内存，常超出消费级显卡容量。
- **既有方法问题**：传统一阶优化器（如Adam）依赖反向传播，需存储激活值，内存开销数倍于推理；参数高效微调（PEFT）方法（如LoRA）虽减少可调参数，但仍需反向传播，内存需求仍显著高于推理。

2)  
- **核心方法**：ZO-ASR是一种零阶优化方法，通过前向传播估计梯度，避免反向传播及激活值存储，显著降低内存占用。
- **关键技术改进**：
  - **多查询机制（q-RGE）**：通过多次查询（如q=8）聚合梯度估计，降低估计噪声，提升优化鲁棒性，尤其适用于复杂语音识别任务。
  - **内存高效设计**：结合SGD优化器，仅需推理级别内存；利用随机种子重生成扰动向量，无需存储，进一步节省内存。
  - **适用于TTA**：扩展至测试时适应，仅通过前向传播使模型适应噪声或域外数据，适用于边缘部署等无法反向传播的场景。
- **工作流程**：分两阶段——梯度估计阶段通过扰动参数执行2*q次前向传播，缓存梯度投影和随机种子；模型更新阶段重生成扰动向量更新权重。

3)  
- **监督域适应任务**：在Whisper-Large-V3上对低资源语言（如印地语、泰语）微调，相比零样本基线，词错误率相对降低最高达18.9%，优于其他零阶方法（如MeZO、LoZO），但性能仍低于一阶Adam。
- **无监督测试时适应任务**：在Wav2Vec2-Base上对噪声及域外数据集（如LibriSpeech、CHiME3）进行适应，性能较一阶Adam有适度下降，但仅需前向传播，为边缘部署提供可行方案。
- **内存效率**：微调Whisper-Large-V3时，GPU内存占用仅为推理级别（约9.5GB），远低于传统方法（需37-56GB）。
</div>

</details>

---
