---
layout: post
title: "arXiv Daily – 2026-01-16"
tags: [arxiv, cs.SD, eess.AS]
---

以下为 2026-01-16（CST，北京时间）窗口内更新的论文中文译文：
- 时间窗口（锚点 08:50 CST）：2026-01-15 08:50 — 2026-01-16 08:50
- 抓取总数：7 篇 | 本页显示：7 篇（去重/过滤后）

## VoiceSculptor: Your Voice, Designed By You
- **Authors**: Jingbin Hu, Huakang Chen, Linhan Ma, Dake Guo, Qirui Zhan, Wenhao Li, Haoyu Zhang, Kangxiang Xia, Ziyu Zhang, Wenjie Tian, Chengyou Wang, Jinrui Liang, Shuhan Guo, Zihang Yang, Bengu Wu, Binbin Zhang, Pengcheng Zhu, Pengyuan Xie, Chuan Xie, Qiang Zhang, Jie Liu, Lei Xie
- **Categories**: eess.AS
- **arXiv**: [https://arxiv.org/abs/2601.10629v1](https://arxiv.org/abs/2601.10629v1)
- **PDF**: [https://arxiv.org/pdf/2601.10629v1](https://arxiv.org/pdf/2601.10629v1)

尽管文本转语音（TTS）技术发展迅速，但开源系统仍缺乏真正遵循指令、对核心语音属性（如音高、语速、年龄、情感和风格）进行细粒度控制的能力。本文提出VoiceSculptor，一个开源统一系统，通过将基于指令的语音设计与高保真语音克隆集成于单一框架，填补了这一空白。该系统能够直接从自然语言描述生成可控的音色，支持通过检索增强生成（RAG）进行迭代优化，并提供跨多维度属性级编辑。设计完成的语音将被渲染为提示波形，并输入克隆模型，以实现下游语音合成的高保真音色迁移。VoiceSculptor在InstructTTSEval-Zh评测中达到开源领域最先进水平，并已全面开源代码与预训练模型，以推动可复现的指令控制TTS研究发展。

<details>
<summary>详细解读</summary>

<div markdown="1">

（全文解读失败：404 Client Error: Not Found for url: https://arxiv.org/pdf/2601.10629v1）
</div>

</details>

---

## HeartMuLa: A Family of Open Sourced Music Foundation Models
- **Authors**: Dongchao Yang, Yuxin Xie, Yuguo Yin, Zheyu Wang, Xiaoyu Yi, Gongxi Zhu, Xiaolong Weng, Zihan Xiong, Yingzhe Ma, Dading Cong, Jingliang Liu, Zihang Huang, Jinghan Ru, Rongjie Huang, Haoran Wan, Peixu Wang, Kuoxi Yu, Helin Wang, Liming Liang, Xianwei Zhuang, Yuanyuan Wang, Haohan Guo, Junjie Cao, Zeqian Ju, Songxiang Liu, Yuewen Cao, Heming Weng, Yuexian Zou
- **Categories**: cs.SD
- **arXiv**: [https://arxiv.org/abs/2601.10547v1](https://arxiv.org/abs/2601.10547v1)
- **PDF**: [https://arxiv.org/pdf/2601.10547v1](https://arxiv.org/pdf/2601.10547v1)

本文介绍了一系列开源音乐基础模型，旨在推动跨任务与跨模态的大规模音乐理解与生成。该框架包含四个核心组件：(1) HeartCLAP，一种音频-文本对齐模型；(2) HeartTranscriptor，专为真实音乐场景优化的鲁棒歌词识别模型；(3) HeartCodec，一种低帧率（12.5 Hz）高保真音乐编解码器，能够在捕捉长程音乐结构的同时保留细粒度声学细节，并支持高效的自回归建模；(4) HeartMuLa，一种基于大语言模型的歌曲生成模型，能够在丰富且用户可控的条件下（如文本风格描述、歌词及参考音频）合成高保真音乐。此外，该模型提供两种专用模式：(i) 细粒度音乐属性控制，允许用户通过自然语言提示指定不同歌曲段落（如前奏、主歌、副歌）的风格；(ii) 简短动感的音乐生成，适用于短视频背景音乐。最后，当模型参数扩展至70亿时，HeartMuLa 性能显著提升。我们首次证明，利用学术规模的数据与GPU资源即可复现 Suno 级别的商业级系统。期望这些基础模型能为未来研究提供有力基准，并推动多模态内容生产的实际应用。

<details>
<summary>详细解读</summary>

<div markdown="1">

（全文解读失败：404 Client Error: Not Found for url: https://arxiv.org/pdf/2601.10547v1）
</div>

</details>

---

## Stable Differentiable Modal Synthesis for Learning Nonlinear Dynamics
- **Authors**: Victor Zheleznov, Stefan Bilbao, Alec Wright, Simon King
- **Categories**: cs.SD, cs.LG, eess.AS, physics.comp-ph
- **arXiv**: [https://arxiv.org/abs/2601.10453v1](https://arxiv.org/abs/2601.10453v1)
- **PDF**: [https://arxiv.org/pdf/2601.10453v1](https://arxiv.org/pdf/2601.10453v1)

模态方法是物理建模合成领域长期采用的一种方法。该方法可扩展至非线性问题，例如弦的高振幅振动情形。通过模态分解，可得到一组密集耦合的非线性常微分方程系统。近期标量辅助变量技术的进展，使得为此类非线性系统构建显式且稳定的数值求解器成为可能。另一方面，机器学习方法（特别是神经常微分方程）已成功实现从数据中自动建模非线性系统。本研究探讨了如何将标量辅助变量技术与神经常微分方程相结合，构建出能够学习非线性动力学的稳定可微分模型。所提出的方法利用系统模态线性振动的解析解，使得训练后系统的物理参数仍易于获取，无需在模型架构中引入参数编码器。作为概念验证，我们生成了弦非线性横向振动的合成数据，并证明该模型可通过训练复现系统的非线性动力学特性。文中同时提供了声音示例。

<details>
<summary>详细解读</summary>

<div markdown="1">

（全文解读失败：404 Client Error: Not Found for url: https://arxiv.org/pdf/2601.10453v1）
</div>

</details>

---

## RSA-Bench: Benchmarking Audio Large Models in Real-World Acoustic Scenarios
- **Authors**: Yibo Zhang, Liang Lin, Kaiwen Luo, Shilinlu Yan, Jin Wang, Yaoqi Guo, Yitian Chen, Yalan Qin, Zhenhong Zhou, Kun Wang, Li Sun
- **Categories**: cs.SD
- **arXiv**: [https://arxiv.org/abs/2601.10384v1](https://arxiv.org/abs/2601.10384v1)
- **PDF**: [https://arxiv.org/pdf/2601.10384v1](https://arxiv.org/pdf/2601.10384v1)

尽管音频大模型（ALMs）已展现出卓越的性能，但在实际部署中其鲁棒性仍显脆弱。现有评估方法主要依赖合成的高斯噪声或简单的单源干扰，未能捕捉真实物理环境中复杂、多层次的声学动态——即“声学生态”。为弥合这一生态鸿沟，我们提出了 **RSA-Bench**，一个通过高保真听觉场景模拟对ALMs进行压力测试的综合性鲁棒性基准。与传统方法不同，我们通过将多样化的环境声景（涵盖**牧场**、**极端天气**、**教室**和**户外**等场景）在多种干扰强度下自然叠加到纯净语音信号上，构建评估样本。通过在从基础感知到复杂推理的六项核心任务上评估模型，本研究揭示了三个宏观层面的发现：**（I）感知与认知鸿沟**：模型在低层次识别任务中保持相对稳健，但在压力下的高阶推理任务中出现**功能性崩溃**；**（II）场景敏感性**：“类人声”干扰（如背景笑声）比机械噪声更具破坏性，这对模型的听觉注意力机制提出了挑战；**（III）去噪悖论**：标准语音增强技术往往会加剧性能下降，因为ALMs对去噪伪影引入的语义失真高度敏感。

<details>
<summary>详细解读</summary>

<div markdown="1">

（全文解读失败：404 Client Error: Not Found for url: https://arxiv.org/pdf/2601.10384v1）
</div>

</details>

---

## Self-supervised restoration of singing voice degraded by pitch shifting using shallow diffusion
- **Authors**: Yunyi Liu, Taketo Akama
- **Categories**: cs.SD
- **arXiv**: [https://arxiv.org/abs/2601.10345v1](https://arxiv.org/abs/2601.10345v1)
- **PDF**: [https://arxiv.org/pdf/2601.10345v1](https://arxiv.org/pdf/2601.10345v1)

在歌唱音频制作中，音高变换是一项核心功能。然而，传统的信号处理方法存在众所周知的权衡问题，例如共振峰偏移和机械感音色失真，且音高偏移幅度越大，这些问题越显著。本文通过将音高变换重构为一种修复问题，以实现高质量的歌唱音频音高变换：给定一段经过音高变换（因而包含失真）的音频，我们在保持其旋律与时序的同时，恢复出自然听感的演唱效果。具体而言，我们采用一个轻量级的梅尔谱扩散模型，该模型由帧级声学特征（如基频、音量及内容特征）驱动。我们通过自监督方式构建训练数据对：先施加音高变换以模拟实际失真，再将其还原以保留真实参考。在精选的歌唱数据集上，与代表性经典基线方法相比，所提方法显著降低了音高变换引入的失真，这一结论在统计指标和成对声学测量中均得到验证。结果表明，基于修复的音高变换方法有望成为歌唱制作流程中抗失真的可行技术路径。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：传统信号处理方法（如重采样、相位声码器、PSOLA、分析-合成声码器）在音高转换时存在固有缺陷，包括共振峰偏移、机器人音色、相位失真和瞬态模糊等问题，且音高偏移幅度越大，失真越严重。  
- **既有方法问题**：这些方法通常需要精细调参以避免可听伪影，且难以在保持音高准确性的同时消除伪影。而现有的数据驱动方法（如基于扩散的歌声合成/转换系统）大多依赖说话人嵌入，难以直接应用于未见歌手的音高转换。

2)  
- **核心方法**：论文将音高转换重构为一个**自监督的修复问题**。其核心是一个**浅层扩散模型**，用于去除由传统声码器引入的伪影，同时保持音高和音色。  
- **具体解决方案**：  
  - **自监督数据对生成**：使用WORLD声码器对原始音频进行正向（如升高N个半音）和反向（降低N个半音）的音高转换，生成带有伪影的音频作为输入，原始音频作为重建目标。这解决了缺乏完美音高转换配对数据的问题。  
  - **轻量级Mel谱扩散模型**：模型在Mel谱域运行，是一个一维时序U-Net。它被**条件特征**驱动，包括：  
    - 从伪影音频中提取的基频（F0）。  
    - 音量包络。  
    - 来自ContentVec的说话人无关的内容特征。  
  - **浅层扩散与快速采样**：采用仅需少量（如10步）去噪步数的浅层扩散策略，并使用DPM-Solver加速采样，实现高效推理。  
  - **联合训练目标**：除了标准扩散损失，还加入了预测Mel谱和F0的L1辅助损失，以稳定音高和能量的恢复。  
- **架构优势**：该方法结合了WORLD声码器（提供精确、鲁棒的音高轨迹）和扩散模型（强大的生成先验和去伪影能力），实现了对未见歌手的、音高准确的、伪影抑制的音高转换。

3)  
- **任务**：在**歌声音高转换修复**任务上进行了评估，旨在将经过传统方法音高转换后带有伪影的音频，修复为自然、音高准确的歌声。  
- **效果**：在未见过的歌唱数据集上，与多种基线方法（如TD-PSOLA、WORLD、SiFiGAN、Diff-Pitcher）相比，该方法取得了显著更好的效果：  
  - **统计分布指标**：Fréchet Audio Distance (FAD)、Kernel Inception Distance (KID) 和 Maximum Mean Discrepancy (MMD) 得分最低，表明其输出分布最接近真实歌声。  
  - **成对信号指标**：在频谱收敛度（SC）、MFCC距离、基频误差（F0 RMSE）和清浊音错误率（V/UV）上均取得最佳结果，证明了其在频谱保真度、音高准确性和音色保持方面的优越性。
</div>

</details>

---

## MoST: Mixing Speech and Text with Modality-Aware Mixture of Experts
- **Authors**: Yuxuan Lou, Kai Yang, Yang You
- **Categories**: cs.CL, cs.AI, cs.LG, cs.SD
- **arXiv**: [https://arxiv.org/abs/2601.10272v1](https://arxiv.org/abs/2601.10272v1)
- **PDF**: [https://arxiv.org/pdf/2601.10272v1](https://arxiv.org/pdf/2601.10272v1)

本文提出MoST（语音与文本混合模型），这是一种新型多模态大语言模型，通过我们提出的模态感知专家混合架构（MAMoE）实现了语音与文本处理的无缝集成。当前多模态模型通常使用相同参数处理不同模态的表征，忽视了其内在的表征差异，为此我们引入了专用路由路径，能够根据输入类型将词元定向至适配对应模态的专家。MAMoE通过两个互补组件同时增强模态特异性学习与跨模态理解：捕获领域特定模式的模态专用专家组，以及促进模态间信息传递的共享专家。基于此架构，我们开发了高效的转换流程：首先在ASR和TTS数据集上进行策略性后训练，随后使用精心构建的语音-文本指令数据集进行微调，从而适配预训练的MoE语言模型。该流程的关键特点是完全依赖可公开获取的开源数据集即可实现优异性能与数据高效性。在ASR、TTS、音频语言建模及口语问答基准测试中的综合评估表明，MoST在参数量相当的模型中持续保持领先优势。消融研究证实，模态专用路由机制与共享专家设计对所有测试领域的性能提升均有显著贡献。据我们所知，MoST是基于专家混合架构构建的首个完全开源的语音-文本大语言模型。

<details>
<summary>详细解读</summary>

<div markdown="1">

（全文解读失败：404 Client Error: Not Found for url: https://arxiv.org/pdf/2601.10272v1）
</div>

</details>

---

## Nearest Kronecker Product Decomposition Based Subband Adaptive Filter: Algorithms and Applications
- **Authors**: Jianhong Ye, Haiquan Zhao
- **Categories**: eess.AS, cs.IT
- **arXiv**: [https://arxiv.org/abs/2601.10078v1](https://arxiv.org/abs/2601.10078v1)
- **PDF**: [https://arxiv.org/pdf/2601.10078v1](https://arxiv.org/pdf/2601.10078v1)

近年来，基于最近克罗内克积分解的归一化最小均方算法在收敛性能上已展现出优于传统NLMS算法的优势。然而，该算法在处理高度相关的输入信号时，收敛速度会出现显著下降。为解决这一问题，本文提出一种基于I型NKP的归一化子带自适应滤波算法，即NSAF-NKP-I。但该算法的计算开销远高于NLMS-NKP算法。值得注意的是，我们提出的增强型II型NKP-NSAF算法在保持同等收敛性能的同时，大幅降低了计算复杂度。此外，为提升算法在脉冲噪声干扰下的鲁棒性，我们进一步提出了两种鲁棒性改进版本：基于最大相关熵准则的鲁棒NSAF-NKP算法和基于对数准则的鲁棒NSAF-NKP算法。文中还对所提算法的计算复杂度、步长范围及理论稳态性能进行了详细分析。为增强NSAF-NKP-II算法在复杂非线性环境中的实用性，我们进一步设计了两种非线性实现方案：基于三角函数链接网络的NKP-NSAF算法和基于Volterra级数展开的NKP-NSAF算法。在主动噪声控制系统中，我们还提出了滤波-x型NSAF-NKP-II算法。通过在回声消除、稀疏系统辨识、非线性处理及主动噪声控制等场景下的仿真实验，验证了所提算法相较于现有先进方法的优越性。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：自适应滤波算法（如NLMS）在处理高度相关输入信号时收敛性能下降。现有方法（如AP、RLS）虽能提升收敛速度，但计算复杂度高。  
- **既有问题**：  
  - NLMS-NKP算法在处理强相关信号时收敛速度显著降低。  
  - 现有NKP分解方法（如RLS-NKP、APA-NKP）涉及矩阵运算，计算开销大。  
  - 传统算法在脉冲噪声或非线性环境下鲁棒性不足。

2)  
- **核心方法**：提出基于最近Kronecker积分解的子带自适应滤波框架，通过改进模型结构和引入鲁棒准则解决上述问题。  
  - **NSAF-NKP-I算法**：将NKP分解与子带处理结合，提升对相关信号的收敛速度，但计算复杂度较高。  
  - **NSAF-NKP-II算法**：优化子带NKP模型结构，在保持与NSAF-NKP-I相当收敛性能的同时，大幅降低计算复杂度。  
  - **鲁棒变体**：  
    - 基于最大相关熵准则（RNSAF-NKP-MCC）和对数准则（RNSAF-NKP-LC），在脉冲噪声环境下通过缩放函数自适应调整步长，增强鲁棒性。  
  - **非线性扩展**：  
    - 基于三角函数链路网络（TFLN-NKP-NSAF）和Volterra级数（Volterra-NKP-NSAF），将子带NKP结构扩展到非线性场景。  
  - **ANC应用**：进一步提出滤波-x NSAF-NKP-II（NKP-FxNSAF）算法，用于主动噪声控制系统。

3)  
- **任务与效果**：  
  - **系统辨识与回声消除**：在强相关输入下，NSAF-NKP-II较NLMS-NKP收敛更快，且计算复杂度低于RLS-NKP和APA-NKP。  
  - **脉冲噪声环境**：RNSAF-NKP-MCC和RNSAF-NKP-LC在α稳定噪声中保持稳定收敛，性能优于NKP-GMCC等现有鲁棒算法。  
  - **非线性处理**：TFLN-NKP-NSAF和Volterra-NKP-NSAF在不对称扬声器失真等非线性场景中，较传统非线性算法获得更低的稳态误差。  
  - **主动噪声控制**：NKP-FxNSAF在ANC系统中实现更快的收敛速度和更高的噪声抑制能力。
</div>

</details>

---
