---
layout: post
title: "arXiv Daily – 2025-10-21"
tags: [arxiv, cs.SD, eess.AS]
---

以下为 2025-10-21（CST，北京时间）窗口内更新的论文中文译文：
- 时间窗口（锚点 08:50 CST）：2025-10-20 08:50 — 2025-10-21 08:50
- 抓取总数：8 篇 | 本页显示：8 篇（去重/过滤后）

## AnyRIR: Robust Non-intrusive Room Impulse Response Estimation in the Wild
- **Authors**: Kyung Yun Lee, Nils Meyer-Kahlen, Karolina Prawda, Vesa Välimäki, Sebastian J. Schlecht
- **Categories**: eess.AS
- **arXiv**: [http://arxiv.org/abs/2510.17788v1](http://arxiv.org/abs/2510.17788v1)
- **PDF**: [http://arxiv.org/pdf/2510.17788v1](http://arxiv.org/pdf/2510.17788v1)

本文针对存在非平稳声音干扰的实际场景，提出了一种鲁棒的房间冲激响应估计方法AnyRIR。该方法采用音乐作为激励信号而非专用测试信号，通过时频域L1范数回归将RIR估计问题公式化，并采用迭代重加权最小二乘法与最小二乘最小残差法进行高效求解。该方案利用非平稳噪声的稀疏特性有效抑制其干扰，在模拟和实测数据上的实验表明：在真实噪声场景与编解码器失配条件下，AnyRIR优于基于L2范数的时域解卷积和频域解卷积方法，能为增强现实/虚拟现实等应用提供鲁棒的RIR估计能力。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：房间脉冲响应（RIR）用于描述声学环境特性，对AR/VR和智能扬声器等应用至关重要。  
- **既有方法问题**：  
  - 传统方法（如指数正弦扫频）需受控环境，在公共场所不实用；  
  - 非平稳噪声（如脚步声、语音）会干扰基于反卷积的估计；  
  - 现有抗噪方法（如MOSAIC）需多次重复测量，灵活性不足。  

2)  
- **核心方法**：提出AnyRIR，使用音乐作为激励信号，通过时频域ℓ₁范数回归估计RIR，并采用IRLS和LSMR高效求解。  
- **解决思路**：  
  - **ℓ₁范数优化**：对残差施加ℓ₁损失，抑制非平稳噪声（异常值）的影响；  
  - **时频域处理**：利用非平稳噪声在时频域的稀疏性，通过权重调整降低噪声主导区间的权重；  
  - **高效计算**：  
    - 使用FFT实现卷积和伴随算子，避免显式构建大矩阵；  
    - 引入均衡预处理（如线性预测逆滤波）改善系统矩阵条件数，加速收敛；  
  - **适用性**：无需专用测试信号，仅依赖背景音乐及音乐识别算法提供的干净参考。  

3)  
- **任务与效果**：  
  - **模拟与真实场景**：在包含非平稳噪声的咖啡馆等环境中，RIR估计误差比ℓ₂范数和频域反卷积方法低约25–30 dB；  
  - **编解码器失配**：在不同码率（如MP3）下仍保持稳定性，误差仅增加约15 dB；  
  - **实际测量**：在实验室厨房录制含干扰噪声的音频，估计EDC与真实RIR高度接近。
</div>

</details>

---

## DELULU: Discriminative Embedding Learning Using Latent Units for Speaker-Aware Self-Supervised Speech Foundational Model
- **Authors**: Massa Baali, Rita Singh, Bhiksha Raj
- **Categories**: cs.SD, cs.CL
- **arXiv**: [http://arxiv.org/abs/2510.17662v1](http://arxiv.org/abs/2510.17662v1)
- **PDF**: [http://arxiv.org/pdf/2510.17662v1](http://arxiv.org/pdf/2510.17662v1)

自监督语音模型在内容驱动任务中取得显著成功，但在捕获说话人验证、日记化及属性分析等任务所需的说话人区分性特征方面仍存在局限。本文提出DELULU模型，通过将外部监督引入伪标签生成过程，构建具有说话人感知能力的自监督基础模型。该模型利用当前最先进的说话人验证模型ReDimNet生成的帧级嵌入向量，在预训练的k-means聚类步骤中引入强说话人区分性归纳偏置，使表征学习与说话人身份对齐。通过结合掩码预测与去噪的双重训练目标，进一步增强了模型的鲁棒性与泛化能力。实验表明，DELULU在一系列说话人中心任务中显著优于现有自监督学习模型：说话人验证等错误率相对提升达62%，在性别、年龄、口音及说话人计数等零样本属性分析任务中持续取得优势。研究证明DELULU可作为说话人感知语音处理的强效通用编码器，即使无需任务特定微调仍能实现卓越性能。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：自监督语音模型在内容驱动任务中表现优异，但在说话人验证、日志化和画像等任务中，对说话人区分性特征的捕捉能力有限。  
- **既有方法问题**：  
  - 传统自监督模型（如HuBERT、WavLM）依赖基于声学特征的聚类生成伪标签，优先考虑语音相似性，抑制了说话人特有的音质、韵律和风格信息。  
  - 伪标签与说话人区分性结构对齐不足，导致模型难以学习鲁棒的说话人表征。  

2)  
- **核心方法**：DELULU通过引入外部监督改进伪标签生成过程，具体包括：  
  - **教师引导聚类**：利用ReDimNet（先进说话人验证模型）提取帧级说话人嵌入，替代纯声学特征指导k-means聚类（k=256），使离散目标编码说话人特性（如音质、韵律）。  
  - **双目标训练**：结合掩码预测和去噪目标：  
    - 掩码预测损失：模型预测被掩码位置的聚类分配，强化说话人身份对齐。  
    - 去噪损失：对带噪语音进行特征对齐，提升模型在噪声环境下的鲁棒性。  
  - **架构适配**：调整卷积步长（16ms帧率）确保师生模型帧级同步，优化时序对齐。  
- **解决效果**：该方法在自监督学习中引入强说话人区分性归纳偏置，在不牺牲通用声学建模的前提下，显著提升说话人信息捕获能力。  

3)  
- **任务与效果**：  
  - **说话人验证**：在VoxCeleb和SITW上，零-shot评估相对错误率降低高达62%（如EER从34.05%降至13.53%）；下游微调后EER进一步降至5.63%。  
  - **零-shot说话人画像**：在性别、年龄、口音检测及说话人计数等任务中，Macro-F1分数全面领先基线模型（如口音检测F1达78.38%）。  
  - **表征分析**：t-SNE可视化显示嵌入空间具有紧凑的说话人簇和清晰的 demographic 结构，证实模型通用性强。
</div>

</details>

---

## SARSteer: Safeguarding Large Audio Language Models via Safe-Ablated Refusal Steering
- **Authors**: Weilin Lin, Jianze Li, Hui Xiong, Li Liu
- **Categories**: cs.SD, cs.CR
- **arXiv**: [http://arxiv.org/abs/2510.17633v1](http://arxiv.org/abs/2510.17633v1)
- **PDF**: [http://arxiv.org/pdf/2510.17633v1](http://arxiv.org/pdf/2510.17633v1)

大型音频语言模型（LALMs）正逐渐成为现实应用场景中不可或缺的多模态基础架构。然而近期研究表明，与文本输入相比，音频输入更容易诱发模型生成有害回复，这为实际部署带来了新的安全隐患。尽管安全对齐技术在纯文本大模型（LLMs）与大型视觉语言模型（LVLMs）中已取得初步进展，但我们发现这些方法直接迁移至LALMs时存在两大局限：1）基于LLM的调控机制因激活值分布差异过大而在音频输入场景下失效；2）基于提示词的防御方案会导致对良性语音查询的过度拒绝。为解决这些问题，我们提出安全消融拒绝导向框架（SARSteer），这是首个面向LALMs的推理时防御方案。该框架通过文本衍生的拒绝导向机制实现安全拒答而无需操纵音频输入，并引入解构式安全空间消融以缓解过度拒绝问题。大量实验表明，SARSteer在显著提升对有害查询拒绝能力的同时，能有效保持对良性请求的响应质量，为LALMs的安全对齐奠定了理论基础。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：大型音频语言模型（LALMs）在语音助手等应用中作用关键，但音频输入比文本更易引发有害回复，带来部署风险。  
- **既有方法问题**：  
  - 基于LLM的激活引导方法因音频与文本隐空间分布差异大而失效；  
  - 基于提示的防御方法（如LVLMs中的自适应提示）在良性语音查询上产生过度拒绝，降低实用性。  

2)  
- **核心方法**：SARSteer通过以下组件解决问题：  
  - **文本引导拒绝方向**：从文本拒绝提示（如“我无法协助”）提取引导向量，避免依赖音频输入分布差异，直接增强对有害查询的拒绝能力；  
  - **分解安全空间消融**：对安全样本进行PCA分析，识别良性语义主导子空间，并从引导向量中去除该成分，减少对良性查询的干扰；  
  - **整体机制**：在推理时结合上述步骤，仅修改隐藏状态，无需微调，实现安全与实用性的平衡。  

3)  
- **任务与效果**：  
  - **安全性**：在Figstep-audio、AdvBench等有害查询数据集上，攻击成功率显著降低（如Qwen2-Audio中从51.6%降至10.8%）；  
  - **实用性**：在AirBench等通用任务中保持性能，同时通过平衡拒绝率指标在有害-安全配对数据上实现更高帮助性（如Kimi-Audio中BRR达88.8%）。
</div>

</details>

---

## AWARE: Audio Watermarking with Adversarial Resistance to Edits
- **Authors**: Kosta Pavlović, Lazar Stanarević, Petar Nedić, Slavko Kovačević, Igor Djurović
- **Categories**: cs.SD, cs.LG, cs.MM
- **arXiv**: [http://arxiv.org/abs/2510.17512v1](http://arxiv.org/abs/2510.17512v1)
- **PDF**: [http://arxiv.org/pdf/2510.17512v1](http://arxiv.org/pdf/2510.17512v1)

当前基于学习的音频水印方法普遍通过在训练中模拟多种失真来追求鲁棒性，但这类替代性失真范围有限且易导致过拟合。本文提出AWARE（抗编辑对抗性音频水印），该方案摒弃了对攻击模拟栈和手工设计可微分失真的依赖，通过在时频域中基于电平比例感知预算进行对抗优化来实现水印嵌入。检测环节采用时序无关的检测器，其配备的比特级读取头（BRH）可将时域证据聚合为每个水印比特的单一评分，从而在失同步和时序裁剪条件下仍能实现可靠解码。实验表明，AWARE在保持高音频质量与语音可懂度（PESQ/STOI指标）的同时，对各类音频编辑操作均能实现稳定的低误码率，其综合性能常优于代表性的学习型音频水印前沿系统。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：传统音频水印方法面临两大挑战：  
  - 对时间轴失步（如变速、裁剪）和波形切割的鲁棒性不足，依赖同步码但检测困难；  
  - 基于深度学习的现有方法依赖训练时模拟失真攻击，易过拟合且泛化能力有限。  
- **既有问题**：攻击模拟覆盖范围窄，无法应对真实场景中的复杂编辑（如拼接、局部删除），且架构未针对音频时序特性优化。

---

2)  
**核心方法通过以下设计解决上述问题**：  
- **对抗性嵌入**：  
  - 在时频域进行优化，避免依赖手工设计的失真模拟栈；  
  - 采用感知约束的幅度修改（保留原始相位），按频带能量比例分配扰动预算，平衡不可感知性与鲁棒性。  
- **比特级读出头（BRH）**：  
  - 通过全局池化将时序证据聚合为每比特的独立分数，消除对帧顺序和绝对位置的依赖；  
  - 支持片段级检测，即使部分内容被删除或重排，仍能从剩余片段中解码水印。  
- **架构优化**：  
  - 使用Mel谱前端提升对频域失真（如滤波、压缩）的适应性；  
  - 卷积核尺寸设为1，避免跨帧混合，确保激活值在裁剪下保持稳定；  
  - 完全弃用全连接层，防止输入长度变化导致失效。

---

3)  
**任务与效果**：  
- 在多种音频编辑任务中（包括低通/高通滤波、MP3压缩、量化、噪声添加、重采样、片段删除、时间缩放等），AWARE均取得接近0%的比特错误率（BER）；  
- 在神经声码器重合成、带阻滤波等挑战性场景下，BER显著低于基线（如AudioSeal、WavMark）；  
- 同时保持高语音质量（PESQ≈4.08）和可懂度（STOI≈0.97），证明其兼顾不可感知性与强鲁棒性。
</div>

</details>

---

## Not All Deepfakes Are Created Equal: Triaging Audio Forgeries for Robust Deepfake Singer Identification
- **Authors**: Davide Salvi, Hendrik Vincent Koops, Elio Quinton
- **Categories**: cs.SD
- **arXiv**: [http://arxiv.org/abs/2510.17474v1](http://arxiv.org/abs/2510.17474v1)
- **PDF**: [http://arxiv.org/pdf/2510.17474v1](http://arxiv.org/pdf/2510.17474v1)

高度逼真的歌声深度伪造技术泛滥，对艺术家形象与内容真实性保护构成严峻挑战。基于声纹的自动歌手识别技术为艺术家和权利持有人提供了防范声音盗用的有效途径，但该领域仍存在诸多待解难题。基于"最具危害性的伪造音频往往具有最高质量"的前提，本研究提出双阶段歌手识别流程：首先采用鉴别模型过滤未能准确复现歌手音色的低质量伪造样本，随后使用仅经过真实录音训练的识别模型，对剩余高质量伪造音频及真实音频进行歌手身份判定。实验表明，该体系在真实与合成内容上的识别性能均显著优于现有基线方法。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：高度逼真的歌声深度伪造技术泛滥，威胁艺术家声音形象和内容真实性保护。  
- **既有方法问题**：  
  - 现有研究多聚焦于深度伪造检测或歌手身份识别，但未有效结合两者。  
  - 低质量伪造音频因声音特征失真，干扰歌手识别模型的准确性。  

2)  
- **核心方法**：提出两阶段流程，优先过滤低质量伪造音频，再对高质量样本进行歌手识别。  
- **阶段一（鉴别器D）**：  
  - 使用轻量卷积神经网络（LCNN），基于CTRSVDD数据集训练，区分真实音频与低质量伪造音频。  
  - 重点降低误报率，确保真实音频不被错误过滤。  
- **阶段二（歌手识别S）**：  
  - 采用ECAPA-TDNN架构，仅使用真实录音训练，提取歌手声音嵌入特征。  
  - 通过余弦距离匹配参考数据库，确定歌手身份。  
- **优势**：  
  - 通过分阶段处理，避免低质量伪造音频干扰识别过程。  
  - 仅依赖真实数据训练，提升模型在实际场景中的泛化能力。  

3)  
- **任务与效果**：  
  - **歌手识别任务**：在CTRSVDD和WILDSVDD数据集上，两阶段流程显著提升性能（EER降低约8%，AUC提升约9%）。  
  - **深度伪造鉴别任务**：鉴别器D在多个数据集中均保持极低误报率（FPR<3%），确保高可靠性。  
  - **整体表现**：ECAPA-TDNN模型在含背景音乐的数据集上优于基线，验证了方法对复杂场景的适应性。
</div>

</details>

---

## TopSeg: A Multi-Scale Topological Framework for Data-Efficient Heart Sound Segmentation
- **Authors**: Peihong Zhang, Zhixin Li, Yuxuan Liu, Rui Sang, Yiqiang Cai, Yizhou Tan, Shengchen Li
- **Categories**: cs.SD, cs.AI
- **arXiv**: [http://arxiv.org/abs/2510.17346v1](http://arxiv.org/abs/2510.17346v1)
- **PDF**: [http://arxiv.org/pdf/2510.17346v1](http://arxiv.org/pdf/2510.17346v1)

基于时频特征的深度学习心音分割方法虽能实现较高精度，但通常依赖大量专家标注数据，这限制了其鲁棒性与实际部署。本文提出TopSeg框架，该框架以拓扑表示为核心，通过多尺度拓扑特征编码心音动态特性，并采用轻量级时序卷积网络配合顺序与时长约束的推理步骤进行解码。为评估数据效率与泛化能力，我们仅使用PhysioNet 2016数据集进行训练（含受试者层级子采样），并在CirCor数据集上进行外部验证。在解码器容量匹配的条件下，拓扑特征始终优于频谱图和包络输入，且在低数据预算时优势最为显著；作为完整系统，TopSeg在相同数据预算下超越基于原生输入的典型端到端基线模型，并在全数据量下保持竞争力。在10%训练数据量的消融实验中，所有尺度特征均被证实具有贡献度，而H_0与H_1特征的结合能产生更可靠的S1/S2定位与边界稳定性。这些结果表明：拓扑感知表征为数据高效的跨数据集心音分割提供了强归纳偏置，在标注数据有限的实际场景中具有应用价值。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：心脏病是全球主要死因，心音图（PCG）分割有助于心脏诊断。现有深度学习方法依赖大规模标注数据，在数据稀缺时性能下降；传统手工特征（如包络线）对噪声敏感且难以捕捉复杂时间结构。  
- **既有问题**：  
  - 深度模型需大量标注数据，标注成本高且易受噪声影响；  
  - 包络线等特征鲁棒性差，对病理心音适应性不足；  
  - 缺乏能在有限数据下保持鲁棒性的特征表示。  

2)  
- **核心方法**：提出TopSeg框架，基于拓扑数据分析（TDA）提取多尺度拓扑特征，结合轻量时序卷积网络（TCN）与推理时约束优化。  
- **解决思路**：  
  - **多尺度拓扑编码**：从PCG信号中提取全局（2–8 s）、中观（单心动周期）和细粒度（S1/S2成分）的拓扑描述符，通过持续同调（H0/H1）生成抗噪的持久化景观；  
  - **轻量解码与约束推理**：TCN映射特征为帧级概率，推理时通过凸优化引入生理先验（如事件顺序、持续时间），提升边界稳定性；  
  - **数据效率与泛化**：拓扑特征对扰动不敏感，其几何结构先验减少对标注数据的依赖，支持跨数据集迁移。  

3)  
- **任务与效果**：在PCG分割任务中，于CirCor数据集上进行外部验证：  
  - 低数据预算（5%–25%）下，拓扑特征在相同解码器中显著优于谱图和包络线输入；  
  - 完整系统在全部数据预算下均超越端到端基线（如LR-HSMM、CLSTM），宏F1最高提升约12%（5%数据）；  
  - 多尺度消融表明，全局、中观和细粒度分支共同提升S1/S2定位及边界稳定性。
</div>

</details>

---

## DDSC: Dynamic Dual-Signal Curriculum for Data-Efficient Acoustic Scene Classification under Domain Shift
- **Authors**: Peihong Zhang, Yuxuan Liu, Rui Sang, Zhixin Li, Yiqiang Cai, Yizhou Tan, Shengchen Li
- **Categories**: cs.SD, cs.AI
- **arXiv**: [http://arxiv.org/abs/2510.17345v1](http://arxiv.org/abs/2510.17345v1)
- **PDF**: [http://arxiv.org/pdf/2510.17345v1](http://arxiv.org/pdf/2510.17345v1)

声学场景分类任务常受设备差异引发的域偏移影响，尤其在标注数据有限时更为显著。现有研究多采用课程学习策略，通过由易到难排序或加权训练样本以优化学习过程，但这类课程通常是静态的——其排序或权重在训练前固定，未能反映样本难度与边际效用会随表征学习动态演变的特性。为突破此局限，我们提出动态双信号课程（DDSC），该训练方案通过每轮迭代融合两种信号实现课程在线自适应：域不变性信号与学习进度信号。时变调度器将双信号融合为样本权重，初期侧重域不变样本，随后逐步加强设备特定样本的权重。DDSC具有轻量化、架构无关、零推理开销等优势。在DCASE 2024任务1标准实验框架下，该方法在多种声学场景分类基线模型及标注预算条件下均能稳定提升跨设备性能，并在未见设备数据划分中取得最显著增益。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：声学场景分类面临设备差异导致的领域偏移问题，尤其在标注数据有限时，模型对未知设备的泛化能力显著下降。  
- **既有方法问题**：现有课程学习方法采用静态课程，即训练前固定样本顺序或权重，忽略了样本难度和边际效用随模型训练动态变化，导致：  
  - 早期过度强调高不变性样本；  
  - 后期对跨设备困难样本关注不足。  

2)  
- **动态双信号课程**：通过每轮训练动态计算两种信号并融合为样本权重，实现自适应课程调度：  
  - **领域不变性信号**：基于原型-后验熵，衡量样本跨设备的鲁棒性（熵越高越不变）；  
  - **学习进度信号**：通过平滑损失变化评估样本当前学习价值（损失波动大则潜力高）。  
- **动态融合机制**：  
  - 使用时变调度器（余弦衰减）融合两信号，早期侧重领域不变性，后期逐步转向高难度样本；  
  - 通过Softmax将分数映射为归一化权重，替换均匀损失加权。  
- **优势**：  
  - 轻量且与模型架构无关；  
  - 无需修改模型结构或增加推理开销；  
  - 通过动态调整平衡跨设备泛化与数据效率。  

3)  
- **任务与效果**：在DCASE 2024 Task 1数据集上评估，涵盖多类基线模型（如CP-Mobile、TF-SepNet等）及低标注比例（5%-100%）：  
  - **整体提升**：在5%标注数据下，平均准确率提升约4.2%，未知设备准确率提升约3.9%；  
  - **跨设备泛化**：在未知设备分集上表现最优，尤其在低资源场景；  
  - **兼容性**：所有基线模型均获得一致改进，且无需架构调整。
</div>

</details>

---

## Event Topology-based Visual Microphone for Amplitude and Frequency Reconstruction
- **Authors**: Ryogo Niwa, Yoichi Ochiai, Tatsuki Fushimi
- **Categories**: physics.app-ph, cs.SD
- **arXiv**: [http://arxiv.org/abs/2510.17092v1](http://arxiv.org/abs/2510.17092v1)
- **PDF**: [http://arxiv.org/pdf/2510.17092v1](http://arxiv.org/pdf/2510.17092v1)

在科学与工程领域，精确振动测量对动态系统分析至关重要，然而现有非接触式方法往往难以兼顾精度与实用性。事件相机虽具备高速微光感知优势，但传统技术无法实现振动幅度与频率的高精度重建。本研究提出基于事件拓扑结构的视觉麦克风，无需外部照明即可直接从原始事件流还原振动信息。通过将拓扑数据分析中的Mapper算法与分层密度聚类相结合，该框架能捕捉事件数据的内在结构，实现幅度与频率的高保真重建。实验表明，本方法较现有技术有显著提升，并能从单一事件流中同步还原多声源信号，推动了无源免光照振动感知技术的前沿发展。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：振动测量在结构健康监测、工业诊断等领域至关重要。非接触式方法（如激光多普勒测振仪）精度高但成本昂贵；高速成像虽更易获取，但高帧率需强照明，可能牺牲空间分辨率。  
- **既有方法问题**：  
  - 事件相机虽具备高速、低光感知优势，但现有方法无法同时高精度重建振动幅度与频率。  
  - 被动方法（如基于伪帧或相位分析）仅能恢复主频率，幅度重建误差大。  
  - 主动方法依赖激光，难以同时测量多振动源，限制了事件相机的高空间分辨率潜力。  

2)  
- **核心方法**：提出基于事件拓扑的视觉麦克风，结合拓扑数据分析中的Mapper算法与分层密度聚类（HDBSCAN），直接从原始事件流中重建振动轨迹。  
- **解决思路**：  
  - **拓扑结构提取**：将事件数据映射到三维时空空间，通过滤波函数（如垂直坐标）划分重叠区间，捕获振动内在几何结构。  
  - **自适应聚类**：使用HDBSCAN对每个区间内事件聚类，无需手动调整阈值，适应振动导致的密度变化，提升鲁棒性。  
  - **轨迹重建**：计算聚类质心并时序连接，形成三维轨迹，投影至时间-位移平面生成波形，保留幅度与频率信息。  
  - **噪声处理**：仅处理正事件（亮度增加），并应用背景活动滤波降低噪声，提高信噪比。  
- **创新点**：  
  - 避免将事件转换为其他表征（如伪帧），直接利用拓扑特征克服幅度重建难题。  
  - 支持多振动源同步分析，充分发挥事件相机的空间分辨率优势。  

3)  
- **任务与效果**：  
  - **单振动源重建**：在铝板实验中，对递增/递减幅度正弦波及语音信号，均实现高精度波形与频谱恢复。  
  - **多振动源分离**：成功从单事件流中同时重建两个扬声器（100Hz与120Hz）的振动，频谱峰值清晰分离。  
  - **量化指标**：归一化互相关系数最高达0.97，MVA误差最低至0.22弧度，显著优于基线方法（如帧积累与相位滤波法）。
</div>

</details>

---
