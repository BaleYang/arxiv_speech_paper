---
layout: post
title: "arXiv Daily – 2025-12-18"
tags: [arxiv, cs.SD, eess.AS]
---

以下为 2025-12-18（CST，北京时间）窗口内更新的论文中文译文：
- 时间窗口（锚点 08:50 CST）：2025-12-17 08:50 — 2025-12-18 08:50
- 抓取总数：6 篇 | 本页显示：6 篇（去重/过滤后）

## A Conditioned UNet for Music Source Separation
- **Authors**: Ken O'Hanlon, Basil Woods, Lin Wang, Mark Sandler
- **Categories**: cs.SD, cs.AI, cs.LG, eess.AS
- **arXiv**: [https://arxiv.org/abs/2512.15532v1](https://arxiv.org/abs/2512.15532v1)
- **PDF**: [https://arxiv.org/pdf/2512.15532v1](https://arxiv.org/pdf/2512.15532v1)

本文提出一种用于音乐源分离的条件化UNet模型。传统音乐源分离通常采用多输出神经网络（主要为UNet架构），每个输出对应预定义乐器词汇表中的特定音轨。与之不同，条件化音乐源分离网络在接收待分离信号的同时，还接受与目标音轨相关的音频查询作为条件输入。这种方法无需严格限定词汇表，从而能够处理更贴近实际应用场景的分离任务。由于缺乏合适的数据集，此类条件化方法的潜力长期未被充分发掘，而近期发布的MoisesDb数据集有效解决了这一问题。最新方法Banquet基于该数据集在大规模词汇表任务中展现出良好性能，但其采用Bandsplit RNN而非UNet架构，且作者声称UNet不适用于条件化音乐源分离。对此我们提出不同观点，设计了一种新型条件化UNet模型QSCNet，通过在稀疏压缩网络中集成条件控制机制来实现音乐源分离。实验表明，在多项分离任务中QSCNet以不足半数参数量实现了超过Banquet 1dB以上的信噪比提升。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：音乐源分离（MSS）传统上依赖于多输出神经网络（如UNet），每个输出对应预定义乐器词汇中的一个音轨。这限制了系统的灵活性，无法处理未知或更细粒度的乐器类别。
- **既有方法问题**：  
  - 固定词汇表方法（如四音轨分离）受限于数据集（如MusDb），难以扩展。  
  - 早期条件化MSS研究因缺乏合适数据集（如多乐器、细粒度标注的MoisesDb）而潜力未充分发挥。  
  - 近期方法Banquet基于Bandsplit RNN，并断言UNet不适合条件化MSS，因其存在信息流问题。

2)  
- **核心方法**：本文提出QSCNet，一种基于UNet的条件化MSS网络。它是对Sparse Compressed Network（SCNet）的改进，通过引入条件化机制解决固定词汇表限制。
- **解决思路**：  
  - **网络结构**：采用SCNet作为基础，其本身是一种UNet变体，包含频带分割下采样/上采样模块和双路径RNN颈部结构，在四音轨任务中表现与BSRNN相当。  
  - **条件化机制**：  
    - 使用音频查询（如乐器片段）作为额外输入，通过预训练的PASST网络提取查询嵌入（embedding）。  
    - 在编码器末端、双路径RNN之前插入单个FiLM（Feature-wise Linear Modulation）层，根据查询嵌入调制网络激活，强调目标乐器的特征。  
    - 相比Banquet（将FiLM置于解码器前），此位置允许乐器上下文在序列化长期处理之前被定义，可能优化信息流。  
  - **参数效率**：QSCNet仅使用一个FiLM模块，模型参数量显著少于Banquet（约40%）。
- **反驳UNet不适用论**：作者认为UNet中的跳跃连接有助于信息流动，且多数多输出MSS网络均为UNet，因此条件化UNet是可行的。

3)  
- **任务与效果**：在MoisesDb数据集上评估：  
  - **六音轨分离任务**（I6：人声、贝斯、鼓、吉他、钢琴、其他）：QSCNet在平均5种乐器（不含“其他”）的SNR上超过Banquet约1.6 dB，且参数量减半。  
  - **细粒度音轨分离任务**（I6E：如将人声分为男/女声等）：QSCNet（仅在粗粒度上训练）仍优于在细粒度上训练的Banquet，平均SNR提升约1 dB。  
  - **多输出基线对比**：QSCNet性能接近专门训练的六音轨SCNet6（差距0.7 dB），但参数量仅为后者的约38%。
</div>

</details>

---

## Time-Varying Audio Effect Modeling by End-to-End Adversarial Training
- **Authors**: Yann Bourdin, Pierrick Legrand, Fanny Roche
- **Categories**: cs.SD, cs.LG
- **arXiv**: [https://arxiv.org/abs/2512.15313v1](https://arxiv.org/abs/2512.15313v1)
- **PDF**: [https://arxiv.org/pdf/2512.15313v1](https://arxiv.org/pdf/2512.15313v1)

深度学习已成为音频效果建模的主流方法，但对于时变系统而言，严格的端到端黑箱建模仍存在挑战。与时不变效果不同，对具有内部调制机制的设备进行建模时，通常需要录制或提取控制信号，以满足传统损失函数对时间对齐的要求。本文提出一种生成对抗网络（GAN）框架，仅利用输入-输出音频录音即可对此类效果进行建模，从而避免调制信号提取的需求。我们设计了一种卷积-循环网络架构，采用两阶段训练策略：首先通过对抗训练使模型在无严格相位约束的条件下学习调制行为的分布特征，随后在监督微调阶段引入状态预测网络（SPN）来估计模型与目标对齐所需的初始内部状态。此外，本文开发了一种基于线性调频序列信号的客观评价指标，用于量化调制精度。通过对经典硬件移相器的建模实验，验证了该方法在完全黑箱条件下捕捉时变动态特性的有效性。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：深度学习已成为音频效果建模的标准方法，但针对**时变系统**（如由低频振荡器驱动的相位器、合唱效果）的严格黑盒建模仍具挑战性。  
- **既有问题**：传统监督方法训练时变效果模型时，通常需要**录制或提取调制信号**（如LFO控制信号）以确保时间对齐，否则模型可能仅学习到调制行为的平均值，无法准确捕捉动态变化。现有方法或依赖调制信号提取，或对数据集和训练过程施加限制（如固定LFO相位），缺乏一种仅基于输入-输出音频录音的端到端黑盒建模方案。

2)  
论文提出一种基于生成对抗网络（GAN）的端到端训练框架，核心方法通过**两阶段策略**解决上述问题：  

- **第一阶段：对抗训练**  
  - 使用卷积-循环架构（SPTVMod）作为生成器，其LSTM层的初始状态**随机初始化**，引入随机性。  
  - 训练仅依赖**对抗损失**和极低权重的谱损失（MR-STFT），使生成器学习目标效果的调制行为分布，而**无需严格相位对齐**。这避免了提取调制信号的需求。  
  - 引入**模式寻求（Mode Seeking）正则化**，防止生成器忽略随机初始状态导致调制行为单一（模式崩溃），确保调制对初始状态敏感。  

- **第二阶段：监督微调**  
  - 禁用对抗目标，转而使用**谱损失**进行优化，并引入**状态预测网络（SPN）**。  
  - SPN分析当前处理窗口的输入和输出信号，**预测生成器所需的初始内部状态**，使模型的调制相位与目标数据同步，实现时间对齐。  
  - 此阶段稳定训练，提供感知相关的优化目标，并作为最终评估依据。  

- **辅助创新**：  
  - 开发了基于**啁啾序列信号**的客观调制度量（Lmod），用于量化调制准确性，作为对抗训练阶段的停止准则，弥补了谱损失对相位不敏感的不足。

3)  
- **任务**：在**硬件相位器效果**的黑盒建模任务上进行验证，针对两种不同LFO速率（慢速1.3秒周期、快速0.3秒周期）的数据集。  
- **效果**：  
  - 方法成功**捕捉了时变动态**，在仅使用输入-输出音频录音、不依赖调制信号提取的情况下，生成了具有周期性调制的输出。  
  - 调制度量显示模型能学习到接近目标LFO频率的调制行为。  
  - 经过监督微调后，输出音频的**频谱质量得到提升**，但调制相位同步的准确性对最终谱损失有显著影响。
</div>

</details>

---

## O-EENC-SD: Efficient Online End-to-End Neural Clustering for Speaker Diarization
- **Authors**: Elio Gruttadauria, Mathieu Fontaine, Jonathan Le Roux, Slim Essid
- **Categories**: cs.LG, cs.SD, eess.SP
- **arXiv**: [https://arxiv.org/abs/2512.15229v1](https://arxiv.org/abs/2512.15229v1)
- **PDF**: [https://arxiv.org/pdf/2512.15229v1](https://arxiv.org/pdf/2512.15229v1)

本文提出O-EENC-SD：一种基于EEND-EDA的端到端在线说话人日志系统，其创新在于引入了基于RNN的在线预测拼接机制。我们特别设计了一种新颖的质心优化解码器，并通过严格的消融实验验证了其有效性。相较于现有方法，本系统具有显著优势：相比无监督聚类方法，它无需调整超参数；相比当前计算成本较高的在线端到端方法，它具有更高的效率。在CallHome数据集上的实验表明，在双人电话对话语音场景下，O-EENC-SD的性能与当前最优方法相当。结果显示，即使在处理无重叠的独立语音片段时，该系统仍能在说话人错误率与计算复杂度之间取得优异平衡，展现出极高的运行效率。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：在线说话人日志任务中，传统方法常将端到端模型与聚类或缓冲策略结合以处理流式数据。  
- **既有问题**：  
  - 无监督聚类方法依赖大量超参数调优，且存在训练与推理间的性能差距。  
  - 基于缓冲的策略（如STB）需要较大的缓冲区（如≥100秒），导致计算成本高昂，难以在资源受限的边缘设备上部署。  

2)  
论文提出O-EENC-SD系统，核心方法通过端到端在线神经聚类解决上述问题：  
- **系统框架**：  
  - 基于EEND-EDA模型处理音频块，生成局部说话人吸引子。  
  - 引入RNN（GRU）进行在线神经聚类，通过维护动态更新的说话人质心（centroid）来解决块间的说话人排列问题。  
- **关键创新**：  
  - **质心优化解码器**：使用Transformer解码器，结合当前块的吸引子与一个“幽灵说话人”嵌入，对质心进行上下文感知的细化，提升聚类匹配准确性。  
  - **损失函数设计**：结合全局与块级别的EEND-EDA损失，以及聚类分类损失和聚类后的日志损失，实现端到端优化。  
- **优势**：  
  - 无需超参数调优，避免了无监督聚类的灵活性不足问题。  
  - 计算高效：通过紧凑的质心表示替代大型缓冲区，支持非重叠块处理，显著降低计算复杂度。  

3)  
- **任务**：在双人电话对话语音（CallHome数据集）的在线说话人日志任务上进行评估。  
- **效果**：  
  - 在100秒缓冲区、5秒延迟下，取得9.33%的DER，与当前最优方法竞争。  
  - 在低计算预算下（如10秒缓冲区、无重叠块），DER为10.75%，优于依赖大型缓冲区的基线方法。  
  - 消融实验表明，质心优化解码器将聚类准确率从90%提升至93%，显著降低整体DER。
</div>

</details>

---

## On the Use of Self-Supervised Representation Learning for Speaker Diarization and Separation
- **Authors**: Séverin Baroudi, Hervé Bredin, Joseph Razik, Ricard Marxer
- **Categories**: eess.AS
- **arXiv**: [https://arxiv.org/abs/2512.15224v1](https://arxiv.org/abs/2512.15224v1)
- **PDF**: [https://arxiv.org/pdf/2512.15224v1](https://arxiv.org/pdf/2512.15224v1)

近年来，自监督语音模型（如wav2vec2.0和WavLM）已被证明能显著提升多种下游语音任务的性能，尤其在低资源场景下。然而，针对说话人日志和语音分离等任务的评估研究仍较为有限。本文探究了近期自监督语音表征在这两项与说话人身份相关任务中的表现质量，指出当前文献中存在的不足主要源于现有基准测试的局限性，特别是评估数据集缺乏多样性，以及与日志和分离任务相关的下游系统种类不足。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：自监督语音表示模型（如wav2vec2.0、WavLM）在语音识别等任务中表现出色，但在说话人日志和语音分离任务上的评估仍有限。  
- **既有问题**：  
  - 现有研究多集中于单一模型（如WavLM），缺乏对不同自监督模型（如HuBERT、wav2vec2.0）的广泛评估。  
  - 常用评估基准（如SUPERB）存在数据集单一性（依赖LibriMix）和领域不匹配问题，可能引入偏差。  
  - 下游系统架构差异（如SUPERB与最新方法）可能影响自监督表示的有效性分析。

2)  
- **核心方法**：本文通过系统性基准测试，评估多种自监督语音表示模型在说话人日志和语音分离任务上的性能，并分析其内部表示。  
- **解决思路**：  
  - **模型多样性**：评估包括wav2vec2.0、HuBERT、WavLM、Conversational WavLM和w2v-BERT在内的模型，覆盖不同预训练数据集（LibriSpeech、会话数据）和预训练任务（预测型、对比型）。  
  - **数据集选择**：使用DIHARD3（日志任务）和WSJ0（分离任务）作为评估数据集，避免LibriMix可能带来的领域偏差。  
  - **下游架构**：采用Pyannote的端到端分割模型（日志）和时域分离网络（TasNet）及其变体（ConvTasNet、DPRNN、SepFormer），确保与最新方法对齐。  
  - **层间分析**：对每个自监督模型进行分层激活分析，探究预训练数据和任务对下游性能的影响，并利用w2v-BERT（结合对比与预测学习）直接比较两种学习范式。  
- **关键设计**：  
  - 使用冻结的自监督模型提取表示，避免微调带来的混淆。  
  - 通过可学习的加权平均聚合不同层的表示，以识别对任务贡献最大的模型部分。

3)  
- **任务与效果**：  
  - **说话人日志**：在DIHARD3数据集上，所有自监督模型均优于基线（SincNet特征），相对提升约8%。Conversational WavLM和w2v-BERT表现最佳，分别相对提升26%和25%，显著降低错误率。  
  - **语音分离**：在WSJ0-2mix数据集上，自监督表示的加入普遍提升分离性能（SDRi指标）。Conversational WavLM和w2v-BERT在ConvTasNet和DPRNN上带来约9-11%的相对提升，但在SepFormer上增益较小，表明架构依赖性。  
- **主要发现**：预训练数据集类型（会话数据优于单说话人数据）和学习任务（预测型优于对比型）对性能有显著影响，且模型激活层因任务而异。
</div>

</details>

---

## BEAT2AASIST model with layer fusion for ESDD 2026 Challenge
- **Authors**: Sanghyeok Chung, Eujin Kim, Donggun Kim, Gaeun Heo, Jeongbin You, Nahyun Lee, Sunmook Choi, Soyul Han, Seungsang Oh, Il-Youp Kwak
- **Categories**: cs.SD, cs.LG
- **arXiv**: [https://arxiv.org/abs/2512.15180v1](https://arxiv.org/abs/2512.15180v1)
- **PDF**: [https://arxiv.org/pdf/2512.15180v1](https://arxiv.org/pdf/2512.15180v1)

音频生成技术的快速发展增加了环境声音被恶意篡改的风险，这促使ESDD 2026挑战赛成为首个大规模环境声音深度伪造检测基准。我们提出BEAT2AASIST模型，该模型在BEATs-AASIST基础上进行扩展，将BEATs提取的声学表征沿频率或通道维度拆分，并通过双分支AASIST结构进行处理。为增强特征表达能力，我们引入基于拼接、CNN门控及SE门控策略的top-k Transformer层融合机制。此外，采用基于声码器的数据增强方法以提升模型对未知伪造手段的鲁棒性。在官方测试集上的实验结果表明，所提方法在挑战赛各任务中均取得了具有竞争力的性能。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：音频生成技术（如TTA/ATA）的进步带来了环境声音深度伪造（ESDD）的安全风险。现有研究多集中于语音深度伪造检测，使用wav2vec2等自监督模型作为前端。
- **既有问题**：环境声音深度伪造检测更具挑战性，因为声学条件多变、声音类别多样。现有方法缺乏针对环境音频的专用模型，且需提升对未知伪造方法和低资源黑盒场景的泛化能力。

2)  
论文提出的BEAT2AASIST模型通过以下核心方法解决上述问题：
- **双分支架构**：在BEATs编码器提取特征后，沿频率或通道维度分割特征，分别输入两个独立的AASIST分支处理。频率分割能学习频域相关的伪造线索，通道分割能捕获通道间特定模式，二者互补增强特征判别力。
- **多层融合策略**：融合BEATs编码器的top-k层表示，而非仅用最后一层，以获取更丰富、鲁棒的特征。具体采用三种策略：
  - 拼接融合：直接拼接各层输出。
  - CNN门控融合：使用CNN从输入梅尔谱计算各层权重，实现输入自适应的层强调。
  - SE门控融合：从各层输出直接计算权重，建模全局通道依赖。
- **声码器数据增强**：使用HiFi-GAN等高质量声码器合成伪造音频，增加训练数据多样性，提升模型对未知伪造攻击和黑盒条件的泛化能力。

3)  
- **任务**：在ESDD 2026挑战赛的两个赛道上进行评估：
  - Track 1：泛化到未见过的TTA/ATA生成器。
  - Track 2：极低资源黑盒设置下的性能。
- **效果**：在官方测试集上取得有竞争力的性能：
  - Track 1：最佳系统（集成模型）测试EER为1.60%，优于基线（1.88%）。
  - Track 2：最佳系统测试EER为0.35%，显著优于基线（0.75%），并在该赛道获得第三名排名。
</div>

</details>

---

## Synaspot: A Lightweight, Streaming Multi-modal Framework for Keyword Spotting with Audio-Text Synergy
- **Authors**: Kewei Li, Yinan Zhong, Xiaotao Liang, Tianchi Dai, Shaofei Xue
- **Categories**: cs.SD
- **arXiv**: [https://arxiv.org/abs/2512.15124v1](https://arxiv.org/abs/2512.15124v1)
- **PDF**: [https://arxiv.org/pdf/2512.15124v1](https://arxiv.org/pdf/2512.15124v1)

开放词汇关键词检测在连续语音流中具有广泛的实际应用价值。尽管不同模态在关键词检测中的作用日益受到关注，其有效性已得到认可，但多模态集成带来的参数量增加以及端到端部署的限制，制约了此类模型的实际应用。为应对这些挑战，我们提出了一种轻量级、流式多模态框架。首先，我们聚焦于多模态注册特征，通过减少语音注册中的说话人特定（声纹）信息来提取与说话人无关的特征。其次，我们有效融合了语音与文本特征。最后，我们引入了一种流式解码框架，该框架仅需编码器提取特征，随后通过我们的三种模态表示进行数学解码。在LibriPhase和WenetPrase数据集上的实验验证了模型的性能。与现有流式方法相比，本方法以显著更少的参数量实现了更优的性能。

<details>
<summary>详细解读</summary>

<div markdown="1">

1)  
- **研究背景**：开放词汇关键词唤醒在连续语音流中具有重要应用价值。现有方法主要面临两个问题：
  - **模型复杂度与部署限制**：多模态融合显著增加了模型参数量，且多数端到端模型依赖精确的词边界对齐，难以满足资源受限设备上低延迟、轻量化的流式部署需求。
  - **流式能力不足**：现有轻量流式模型多局限于定制化唤醒，缺乏开放词汇能力；而基于固定窗口的流式方法在处理不同长度关键词时性能波动大。

2)  
论文提出 **Synaspot**，一个轻量级、支持流式的多模态关键词唤醒框架，通过以下核心设计解决上述问题：

- **多模态灵活注册与特征增强**：
  - 支持音频、文本及混合（音频-文本）三种注册模式，提升系统灵活性与鲁棒性。
  - 在音频编码器中引入**说话人分类器并进行梯度反转**，减少语音注册中的说话人相关（声纹）信息，提取更鲁棒的说话人无关特征。
  - 使用**加性角度间隔损失**训练音素分类器，增大音素间边界，减少误报。
  - 通过**对比学习**将音频、文本及混合特征对齐到共享嵌入空间，增强多模态协同。

- **轻量流式解码架构**：
  - **分离编码与解码**：在线推理时仅需运行单一的音频编码器，对输入音频流进行分块、实时提取帧级嵌入。
  - **数学解码**：利用预先计算并缓存的三种注册嵌入（音频、文本、混合），与流式音频嵌入进行帧级相似度计算，无需复杂解码模型。
  - 通过**因果平滑**和**滑动窗口聚合**处理原始相似度得分，生成最终唤醒置信度，支持变长关键词的流式检测。

- **整体优势**：该设计实现了模型参数量大幅降低（仅0.9M），同时支持真正的低延迟流式处理，克服了固定窗口方法的局限。

3)  
在以下任务和数据集上验证了效果：
- **英文任务**（LibriPhase）：在Easy和Hard测试集上，综合使用多模态注册的Synaspot模型取得了最佳性能（例如Hard集EER 27.29%， AUC 79.15%），显著优于同期文本注册基线，且参数量更少。
- **中文任务**（WenetPhrase）：验证了方法的泛化性。在流式场景下，其性能优于固定窗口的非流式基线模型，展示了更好的计算效率与灵活性。
- **效果总结**：模型在保持轻量化（0.9M参数）的同时，实现了高效的流式开放词汇关键词唤醒，在英中任务上均达到了性能与效率的优越平衡。
</div>

</details>

---
